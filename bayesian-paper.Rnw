\documentclass[12pt]{article}
% \usepackage{geometry}                % See geometry.pdf to learn the layout options. There are lots.
% \geometry{letterpaper}                   % ... or a4paper or a5paper or ...
%\usepackage{graphicx}
\usepackage[font=small,skip=5pt]{caption}
\usepackage{subcaption}
\usepackage{afterpage}
\usepackage{amssymb}
\usepackage{natbib}
\usepackage{amsmath}
\usepackage{amsfonts}
% \usepackage{color}
\usepackage{multirow}
\usepackage{rotating}
\usepackage[dvipsnames,svgnames,table]{xcolor}
\usepackage{hyperref}
\graphicspath{{figure/}}
% \usepackage{endfloat} % Figures to the end of the document

\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png}
%---------------------------------------------------
%                 Editing Commands
%\newcommand{\hh}[1]{{\color{magenta} #1}}
%\newcommand{\svp}[1]{{\color{orange} #1}}
\newcommand{\eh}[1]{{\color{cyan} #1}}

\usepackage[colorinlistoftodos]{todonotes}
%                 Editing Commands
\newcommand{\done}[2][inline]{\todo[color=SpringGreen, #1]{#2}}  % for todos that have been seen and dealt with
\newcommand{\meh}[2][inline]{\todo[color=White, #1]{#2}}   % for todos that may no longer be relevant
\newcommand{\comment}[2][inline]{\todo[color=SkyBlue, #1]{#2}} % for comments that may not be "to-do"s
\newcommand{\newtext}[1]{\todo[inline, color=White]{ \color{OliveGreen}{#1}}} % new text - not necessarily something to be done
\newcommand{\newdo}[1]{\todo[inline, color=Lime]{#1}} % new to do item
\newcommand{\hh}[2][inline]{\todo[color=magenta,#1]{#2}}
\newcommand{\svp}[2][inline]{\todo[color=orange,#1]{#2}}


%---------------------------------------------------
%                 Placing Figures


%---------------------------------------------------
% Define new environment
\newtheorem{theorem}{Theorem}[section]
\newtheorem{algorithm}[theorem]{Algorithm}
%---------------------------------------------------

%\pdfminorversion=4
% NOTE: To produce blinded version, replace "0" with "1" below.
\newcommand{\blind}{0}

% DON'T change margins - should be 1 inch all around.
\addtolength{\oddsidemargin}{-.5in}%
\addtolength{\evensidemargin}{-.5in}%
\addtolength{\textwidth}{1in}%
\addtolength{\textheight}{1.3in}%
\addtolength{\topmargin}{-.8in}%


\begin{document}

%\bibliographystyle{natbib}

\def\spacingset#1{\renewcommand{\baselinestretch}%
{#1}\small\normalsize} \spacingset{1}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\if0\blind
{
  \title{\bf A Bayesian approach to visual inference}
  \author{Susan VanderPlas, Eric Hare\thanks{
    The authors gratefully acknowledge funding from the National Science Foundation Grant \# DMS 1007697. All data collection has been conducted with approval from the Institutional Review Board IRB 10-347}\hspace{.2cm}\\
    Department of Statistics and Statistical Laboratory, Iowa State University\\
    and \\
    Heike Hofmann\\
    Department of Statistics and Statistical Laboratory, Iowa State University}
  \maketitle
} \fi

\if1\blind
{
  \bigskip
  \bigskip
  \bigskip
  \begin{center}
    {\LARGE\bf A Bayesian approach to visual inference}
\end{center}
  \medskip
} \fi

\bigskip
\begin{abstract}
Graphics play a crucial role in statistical analysis and data mining. The lineup protocol for experimentally testing graphics has traditionally used p-values to identify plots which are significantly visually distinct from distractor plots, but this approach does not easily translate to examining randomly generated plots to determine the strength of the distractor effect. This study presents a bayesian approach to visual inference, using bayes factors to examine the difference in signal strength in two-target statistical lineups.
\end{abstract}

\noindent%
{\it Keywords:}  Visual inference, Lineup protocol, \hh{XXX Other keywords?}.
\vfill

\newpage
\spacingset{1.45} % DON'T change the spacing!

\tableofcontents
\newpage

<<setup, echo = FALSE, message = FALSE, warning = FALSE>>=
options(replace.assign=TRUE,width=70, digits=2)
require(knitr)
opts_chunk$set(fig.path='figure/', cache.path='cache/', fig.align='center', fig.width=5, fig.height=5, par=TRUE, cache=TRUE, concordance=TRUE, autodep=TRUE, message=F, warning=F)

library(dplyr)
@

\section{Introduction}
Graphics are an important component of big data analysis, providing a mechanism for discovering unexpected patterns in data. Pioneering research by \citet{gelman:2004}, \citet{buja:2009} and \citet{majumder:2011} provide methods to quantify the significance of discoveries made from visualizations.
%Although, there have been major advances in statistical graphics over the years, for example, systems like R \citep{R} provide high quality static graphics, and very recently some access to interactive graphics. But the problem remains that graphics are not widely considered to be a part of inferential statistics.
\citet{buja:2009} introduced two protocols, the Rorschach and the lineup protocol, which bridge the gulf between traditional statistical inference and exploratory data analysis. The Rorschach protocol consists of a set of $m$ (usually, $m=20$) plots (called the {\it null plots}) rendered from data that is consistent with a given null model. That way, the Rorschach protocol helps to understand the extent of randomness in the null model. Under the lineup protocol, a plot of the observed data is placed randomly among a set of $m-1$ null plots.
Human observers are then asked to  examine the lineup and to identify the most different plot. If observers identify the data plot, this is quantifiable evidence against the null hypothesis.
The lineup protocol places a statistical plot firmly in the framework of hypothesis tests: a plot of the data is considered to be the test statistic, which is compared against the sampling distribution under the null hypothesis represented by the null plots.
Obviously, the null generating mechanism, i.e.\ the method of obtaining the data for null plots, is crucial for both the lineup and the Rorschach protocol.
The null hypothesis directly affects the choice of null generating method.
Null generating methods are typically based on (a) simulation, if the null hypothesis allows us to directly specify a parametric model, (b) sampling, as for example in the case of large data sets, or (c) permutation of the original data \citep[see e.g.\ ][]{Good05}, which allows for non-parametric testing  that preserves marginal distributions  while ensuring independence in higher dimensions.
%In the experimental data that we analyzed the null generating methods used were permutation methods and direct simulation from a null model.

The lineup protocol was formally tested in a head-to-head comparison with the equivalent conventional test in \citet{majumder:2011}. The experiment utilized human subjects from Amazon's Mechanical Turk \citep{turk} and used simulation to control conditions. The results suggest that  visual inference is comparable to conventional tests in a controlled conventional setting. This provides support for its appropriateness for testing in real exploratory situations where no conventional test exists. Interestingly, the power of a visual test increases with the number of observers engaged to evaluate lineups, and the pattern in results suggests that the power will provide results consistent with practical significance \citep{kirk:1996}.

\comment{Should cite Adam's papers that examined some null plots as well. Could even possibly analyze some of that data later on as a proof of concept.}

\subsection{Analysis of Statistical Lineups}
\comment{Brief overview of standard analysis and analysis of two-target lineups. Cite jcgs paper for two target lineups, methods paper(s) for analysis of lineup data.}

\section{A Bayesian's Statistical Lineup}
Let $p_i$, $i = 1, ..., m$ be the probability that plot $i$ is picked out of a lineup of $m$ panels. We know that $0 \le p_i \le 1$ with $\sum_{i=1}^m p_i = 1$.
We can assign an uninformative prior probability to $p$ by using a flat Dirichlet distribution (a uniform distribution over the $(m-1)$ simplex). An uninformative proior is desireable because a priori we assume that the plots are all equally likely to be selected by a participant.

We will use the following model:
\begin{eqnarray*}
\alpha &=& (\alpha_1, \alpha_2, ..., \alpha_m) = \text{concentration hyperparameter}\\
p \mid \alpha &=& (p_1, p_2, ..., p_m) \sim Dir (m, \alpha) \\
x \mid p &=& (x_1, x_2, ..., x_m) \sim Mult (m, p)
\end{eqnarray*}
The posterior distribution is then as follows:
\begin{eqnarray*}
c &=& (c_1, ..., c_m) = \text{ number of picks of each plot} \\
p \mid x, \alpha &\sim& Dir (K, \alpha_1+c_1, \alpha_2+c_2, ..., \alpha_m + c_m)
\end{eqnarray*}
\svp{Should this be $p\mid c, \alpha$?}
\svp{What is $K$? Number of evaluations total? also, since $c$ was used for \# picks, I've changed the threshold $c$ to $t$ below.}
\svp{Need to adjust notation to account for multiple plot selections somehow. Maybe add that extension below? e.g. let $z_{ij}$ represent the selection of plot $i$ as the $j$th plot selected. Then $p_i$ = $\sum_{j = 1}^{20} z_{ij}/\sum_{j = 1}^{20} (z_{ij} \text{ is not null})$ or something?}

For visual inference, we are usually dealing with a null hypothesis of the form `the plot of the data is not in any way different from the null plots'.  Under this null hypothesis the vector of concentration parameters $\alpha$ has to consist of the same values, i.e.\ $\alpha_i = $const. The sum of the concentration parameters $\sum{\alpha}$ can be interpreted as the number of (pseudo)evaluations  under the null hypothesis. Jeffreys' uninformative prior \citep{jeffreys:1946} for this situation is $\alpha = \frac{1}{2}$, corresponding to 10 pseudo-evaluations.
\hh{this is likely a parameter we have to fine-tune, right now it is set to be $\alpha = 1/2$.
For $\alpha = 1$ we need a lot of data (in form of evaluations by observers) in order to get the posterior distribution away from the prior, even if we have a strong signal.}


One of the advantages of this model is that it allows a seamless incorporation of results from multiple picks by using reciprocal weights: if an evaluator identified three panels as the `most different', each of these three panels gets an additional $1/3$ to its overall number of picks $c$.
\svp{This is an advantage over the frequentist model for this situation because it could not easily accommodate multiple solutions? Need to explicitly compare/explain.}

\begin{figure}
\centering
<<prior, echo=FALSE, fig.width = 8, fig.height = 8, out.width='0.7\\textwidth'>>=
library(gtools)
library(reshape2)
library(ggplot2)

m <- 20
alpha <- rep(1/2, m)
lps <- data.frame(rdirichlet(5000, alpha))

lpsm <- melt(lps, measure.var=1:20)
lpsm$variable <- as.numeric(gsub("X", "", lpsm$variable))

qplot(value, geom="density", data=lpsm, fill=I("grey50"),
      colour=I("grey45"), alpha=I(0.5)) +
  facet_wrap(~variable) + xlim(c(0,1)) +
  theme_bw() +
  xlab("Probability to pick plot")
@
\caption{\label{fig:prior}Jeffreys' noninformative prior for any lineup of size 20. }
\end{figure}

<<posterior, echo=FALSE, cache = TRUE, warning=FALSE, message=FALSE>>=
getCounts <- function(response) {
  results <- strsplit(response,split=",")
  wt <- sapply(results, length)
  wt <- 1/rep(wt, wt)
  picks <- factor(as.numeric(unlist(results)), levels=1:20)

  counts <- xtabs(wt~picks)
  as.vector(counts)
}


bfactors <- function(alpha, counts) {
  x <- seq(0,1, by=0.001)
  bf <- lapply(1:20, function(i) {
    pre <- pbeta(x, shape1=alpha[i], shape2=sum(alpha)-alpha[i],
                           lower.tail=FALSE)
    post <- pbeta(x, shape1=alpha[i]+counts[i],
                shape2=sum(alpha)-alpha[i] + sum(counts) - counts[i],
                lower.tail=FALSE)
    post/pre
  })
  # As written, this doesn't have a threshold.
  # Also, bayes factors are the posterior of two different models integrated over the parameter space.
  # So I suspect we should sum first then divide.

  # now get averages
  bfavg <- bf %>% lapply(sum) %>% unlist
  bfmode <- bf %>% lapply(max) %>% unlist

  list(avg = bfavg/length(x), mode = bfmode, factor = bf)
}

bfactors.fix <- function(alpha, counts) {
  x <- seq(0,1, by=0.001)
  bf <- lapply(1:20, function(i) {
    pre <- pbeta(x, shape1=alpha[i], shape2=sum(alpha)-alpha[i],
                           lower.tail=FALSE)
    post <- pbeta(x, shape1=alpha[i]+counts[i],
                shape2=sum(alpha)-alpha[i] + sum(counts) - counts[i],
                lower.tail=FALSE)
    sum(post)/sum(pre)
  })
  # As written, this doesn't have a threshold.
  # This version sums first and then divides.

  # now get averages
  # bfavg <- bf %>% lapply(sum) %>% unlist
  # bfmode <- bf %>% lapply(max) %>% unlist

  list(avg = bf)
}

pre_post_picks <- function(data) {
  # needs to have a picture id
  data.picks <- data %>% group_by(pic_id) %>% do(
    counts = getCounts(.$response_no))
  data.picks <- data.picks %>% group_by(pic_id) %>% mutate(
    picks = sum(counts[[1]]),
    post_mean = list((alpha + counts[[1]])/sum(alpha + counts[[1]])),
    post_mode = list((alpha + counts[[1]] - 1)/sum(alpha + counts[[1]]-1)),
    bfactor = list(bfactors(alpha, counts[[1]])),
    bfactor.fix = list(bfactors.fix(alpha, counts[[1]])),
    pre_prob  = list(pbeta(1/20*2, shape1=alpha, shape2=sum(alpha)-alpha,
                           lower.tail=FALSE)),
    post_prob = list(pbeta(1/20*2, shape1=alpha+counts[[1]],
                           shape2=sum(alpha)-alpha + sum(counts[[1]]) - counts[[1]],
                           lower.tail=FALSE))
  )
  data.picks
}

turk19 <- read.csv("data/turk19_results_anon.csv", stringsAsFactors = FALSE)
turk16 <- read.csv("data/turk16_results.csv", stringsAsFactors = FALSE)
turk1013 <- read.csv("data/turk1013_results.csv", stringsAsFactors = FALSE)

pics19 <- read.csv("data/picture-details-turk19.csv", stringsAsFactors = FALSE)
pics16 <- read.csv("data/picture-details-turk16.csv", stringsAsFactors = FALSE)
pics10 <- read.csv("data/picture-details-turk10.csv", stringsAsFactors = FALSE)

turk19.picks <- pre_post_picks(turk19)
turk16.picks <- pre_post_picks(turk16)
turk1013.picks <- pre_post_picks(turk1013)
@

\begin{figure}
\begin{subfigure}[b]{.49\textwidth}
\caption{\label{fig:lp-104}Example lineup. }
\includegraphics[width=\textwidth]{lineup-images/filebab6558ba4c4-multiple.pdf}
\end{subfigure}
\begin{subfigure}[b]{.49\textwidth}
\caption{\label{fig:posterior}Posterior densities for the choosing panel \#$i$. }
<<pics-turk1013, dependson='posterior', echo=FALSE,  fig.width=8, fig.height = 8, out.width='\\textwidth'>>=
# show one of the results:
i <- 1

lpsXXX <- data.frame(rdirichlet(5000, alpha+turk1013.picks$counts[i][[1]]))
lpsXXXm <- melt(lpsXXX, measure.var=1:20)
lpsXXXm$variable <- as.numeric(gsub("X", "", lpsXXXm$variable))

counts <- turk1013.picks[i, "counts"][[1]][[1]]
#probs <- turk1013.picks[i, "post_prob"][[1]][[1]]
#preprobs <- turk1013.picks[i, "pre_prob"][[1]][[1]]
bfactor <- turk1013.picks[i, "bfactor"]$bfactor[[1]]$avg
dframe <- data.frame(variable = 1:20, Bfactor= round(bfactor,2))

ymax <- 1:20 %>% lapply(function(i) max(density(subset(lpsXXXm, variable == i)$value)$y)) %>% unlist %>% max

qplot(value, geom="density", data=lpsXXXm, fill=I("grey50"),
      colour=I("grey45"), alpha=I(0.5)) +
  facet_wrap(~variable) + xlim(c(0,1)) +
  theme_bw() +
  xlab("Posterior probability to pick plot") +
  ggtitle(sprintf("Pic ID %s (based on %.1f picks)", turk1013.picks$pic_id[i],
                  sum(turk1013.picks$counts[i][[1]]))) +
  geom_text(data=dframe, aes(label = Bfactor), x = 1, y = 0.95*ymax, size = 5,
            colour="grey70", hjust="inward", vjust="inward")

@
\end{subfigure}
\caption{\label{fig:xpl-turk1013} Lineup (left) and posterior densities (right) corresponding to evaluations by independent observers.}
\end{figure}


\begin{figure}
\begin{subfigure}[b]{.49\textwidth}
\caption{\label{fig:lp-104}Example lineup. }
\includegraphics[width=\textwidth]{lineup-images/34fcf946135adb1c03b147897f20b33d.pdf}
\end{subfigure}
\begin{subfigure}[b]{.49\textwidth}
\caption{\label{fig:posterior}Posterior densities for the choosing panel \#$i$. }
<<pics, dependson='posterior', echo=FALSE,  fig.width=8, fig.height = 8, out.width='\\textwidth'>>=

# show one of the results:
i <- 1

lpsXXX <- data.frame(rdirichlet(5000, alpha+turk19.picks$counts[i][[1]]))
lpsXXXm <- melt(lpsXXX, measure.var=1:20)
lpsXXXm$variable <- as.numeric(gsub("X", "", lpsXXXm$variable))

counts <- turk19.picks[i, "counts"][[1]][[1]]
probs <- turk19.picks[i, "post_prob"][[1]][[1]]
preprobs <- turk19.picks[i, "pre_prob"][[1]][[1]]
bfactor <- turk19.picks[i, "bfactor"]$bfactor[[1]]$avg
bfs <- turk19.picks[i, "bfactor"]$bfactor[[1]]$factor
dframe <- data.frame(variable = 1:20, Bfactor= round(bfactor,2))

ymax <- 1:20 %>% lapply(function(i) max(density(subset(lpsXXXm, variable == i)$value)$y)) %>% unlist %>% max

qplot(value, geom="density", data=lpsXXXm, fill=I("grey50"),
      colour=I("grey45"), alpha=I(0.5)) +
  facet_wrap(~variable) + xlim(c(0,1)) +
  theme_bw() +
  xlab("Posterior probability to pick plot") +
  ggtitle(sprintf("Pic ID %s (based on %.1f picks)", turk19.picks$pic_id[i],
                  sum(turk19.picks$counts[i][[1]]))) +
  geom_text(data=dframe, aes(label = Bfactor), x = 1, y = 0.9*ymax, size = 5,
            colour="grey70", hjust="inward", vjust="inward")

@
\end{subfigure}
\caption{\label{fig:xpl-104} Lineup (left) and posterior densities (right) corresponding to evaluations by independent observers.}
\end{figure}

For each individual panel of the lineup, the marginal distributions are Beta distributions. For the distribution of picking panel $i$ the prior distribution is therefore a Beta distribution Beta$(1, 19)$. In the example of Figure~\ref{fig:posterior} we have a Beta distribution of Beta$(\Sexpr{counts[11]+ alpha[11]}, \Sexpr{sum(alpha)+sum(counts)-counts[11]-alpha[11]})$ for panel \#11 and Beta$(\Sexpr{counts[20]+ alpha[20]}, \Sexpr{sum(alpha)+sum(counts)-counts[20]-alpha[20]})$ for panel \#20.


\paragraph{Calculation of the Bayes factor for plot \#$i$}\hfill\newline
In order to assess the strength of the signal of plot \#$i$, we calculate the Bayes Factor, which assesses the posterior odds of the full model described above relative to a model which has uniform probability of selecting each plot. More formally,
\begin{eqnarray}
M_1 & := & \text{Multinomial Dirichlet model with Jeffrey's prior}\\
M_2 & := & \text{Uniform Dirichlet model (equivalent to Jeffrey's prior)}\\
BF & = & P(M_1|c)/P(M_2|c)\\
& = & \frac{\int_{p} P(M_1) f_1(c|p) \pi(p) dp}{}
\end{eqnarray}

%
% \svp{We need to explain the cutoff threshold a bit more - develop the ``why".}
% \hh{XXX after discussion with Susan: put a prior uniform on the cutoff threshold $t$ - either integrate it out or find a mode in the posterior.}
% \hh{XXX  integration seems to work out really well - what do you think? }
%
% In order to assess the strength of the signal of plot \#$i$, we assess the probability that an observer chooses this plot at a pre-specified level $t$ and compare the posterior probability to its prior for a Bayes factor.
% More formally, we define the Bayes factor of choosing plot \#$i$ given threshold level $t$ as
% \[
% B_t(p_i) = \frac{P(p_i > t \mid x, \alpha)}{P(p_i > t \mid \alpha)},
% \]
% where $t$ is a pre-specified threshold with $t \in (0,1)$ and $p_i$ is the probability that an observer chooses plot \#$i$, $1 \le i \le m$, as the most different.
% \svp{``most different" is a bit of a weird phrase given that we're allowing participants to select multiple panels. Perhaps ``observer selects plot ... as visually distinct"?}
%
% \svp{Is this thing $B_t$ technically a bayes factor any more? I would think so, but I'm not sure...?\\Upon further reflection, for a single value of $t$ it's a Bayes factor over a reduced sample space, I believe. However, it doesn't make that much sense to integrate $t$ out if that's the interpretation; rather, just integrate over the entire parameter space $[0,1]$ instead.}
%
% The choice of $t$ is critical: a natural choice would be $t = 1/m$, where $m$ is the size of the lineup. However, the prior probability in a lineup of size 20 is $\Sexpr{round(pbeta(1/20, shape1=alpha[1], shape2=sum(alpha)-alpha[1], lower.tail=FALSE), 3)}$ when using the uninformative prior described above. This puts an upper limit on the Bayes factor of $\Sexpr{round(1/pbeta(1/20, shape1=alpha[1], shape2=sum(alpha)-alpha[1], lower.tail=FALSE), 2)}$ (the reciprocal value of the prior). A higher threshold allows for a higher upper limit on the Bayes factor, e.g.\ a threshold of $t = \frac{2}{m}$ already allows for a Bayes factor of up to \Sexpr{round(1/pbeta(1/20*2, shape1=alpha[1], shape2=sum(alpha)-alpha[1], lower.tail=FALSE),2)}. For the example shown in Figure~\ref{fig:xpl-104}, the posterior probabilities of picking panels \#11 and \#20 with a probability of at least $t = \frac{2}{m}$ are \Sexpr{round(probs[11],4)} and \Sexpr{round(probs[20],4)}, respectively. This corresponds to Bayes factors of  \Sexpr{round(probs[11]/preprobs[11],2)} and \Sexpr{round(probs[20]/preprobs[20],2)}.
% An overview of the Bayes factors $B_t$ for a specific lineup is shown in Figure~\ref{fig:bt-104}.
%
% \begin{figure}
% \begin{subfigure}[b]{.49\textwidth}
% \caption{\label{fig:lp-104-bt}Example lineup. }
% \includegraphics[width=\textwidth]{lineup-images/34fcf946135adb1c03b147897f20b33d.pdf}
% \end{subfigure}
% \begin{subfigure}[b]{.49\textwidth}
% \caption{\label{fig:bfactor}Bayes factors at each value of $t \in (0,1)$. }
% <<Bfactort, echo=FALSE, fig.width=7, fig.height=7>>=
% x <- seq(0,0.9999, by=0.01)
% BFS <- 1:20 %>% lapply(function(i) data.frame(i, x = x, bf=bfs[[i]])) %>% bind_rows
% BFS$capbf <- pmin(BFS$bf, 20)
% qplot(x, capbf,  geom="line", data= BFS) + theme_bw() +
%   facet_wrap(facets = ~i) +
%   ylab("Bayes factor at threshold t") +
%   xlab("Threshold t") #+ ylim(c(0,20))
% @
% \end{subfigure}
% \caption{\label{fig:bt-104} Lineup (left) and Bayes factors at threshold $t$ (right). Note that the Bayes factors for plot \#20 are capped at a value of 20. Uncapped, the Bayes factor for \#20 reaches a mode of over 300. }
% \end{figure}
%
% Instead of deciding for a single value of $t$,
% we integrate over all possible values of $t$ and get the Bayes factor for plot \#$i$ as:
% \[
% B(p_i) = \int_0^1 B_t(p_i) dt = \int_0^1 \frac{P(p_i > t \mid x, \alpha)}{P(p_i > t \mid \alpha)} dt.
% \]

There are different schemes interpreting the Bayes factor. \citet{jeffreys:1961} consider a factor of 5 to 10 as `substantial', and values above 20 as `decisive'.
Alternatively, \citet{kass:1995} consider a factor of 6 to 10 as `strong', and values above 10 as `very strong'.
\FloatBarrier
\hh{XXX investigate Bayes factor of different scenarios, ie ten evaluations, different number of data picks and null picks. How does that compare to the visual distribution $V_3$? (the Binomial like distribution that is adjusted for dependencies between the data and the nulls). }
<<bayes-factor-investigation-params, echo = F>>=
Nruns <- 400
Npicks <- 20
@
We simulated bayes factors arising from the following scenario: Out of \Sexpr{Npicks} evaluations, the target plot was selected $x$ times (null plot selections were randomly generated with $\Sexpr{Npicks}-x$ total selections of null plots). For each value of $x$, this simulation was run \Sexpr{Nruns} times, and the results are shown in Figure \ref{fig:bayes-factor-investigation-Target} (target plot bayes factors) and Figure \ref{fig:bayes-factor-investigation-Null} (null plot bayes factors). The target plot bayes factors were identical across all \Sexpr{Nruns} simulation runs, but the null plot bayes factors were not, as a result, the target bayes factor plot shows a clear linear relationship, while the null bayes factor plot shows a series of boxplots representing the distribution of bayes factors for each of 19 null plots in each of \Sexpr{Nruns} simulation runs with $x$ between 0 and \Sexpr{Npicks}.

<<bayes-factor-investigation, echo = F>>=
# Investigate Bayes factor of different scenarios, i.e. 10 evaluations with different number of data picks and null picks.
library(purrr)
# Plot 1 = data plot
bf.sim <- 0:Npicks %>%
  map_df(.f = function(i) {
    1:Nruns %>%
      map_df(.f = function(j){
        data.frame(
          pic_id = sprintf("%02d.%02d", i, j),
          response_no = as.character(c(rep(1, i), sample(2:20, size = (Npicks - i), replace = T))))
      })
  })
tmp <- pre_post_picks(bf.sim)
tmp %<>%
  mutate(data.picks = stringr::str_extract(pic_id, "^\\d{1,}") %>%
           as.numeric) %>%
  arrange(data.picks)

# Get bayes factors for signal and null plots out
bf <- 1:nrow(tmp) %>%
  map_df(.f = function(i) {
    x <- tmp[i,]
    data_frame(
      pic_id = x[["pic_id"]],
      type = c("target", rep("null", 19)),
      bf = unlist(x$bfactor[[1]]$avg))
  }) %>%
  mutate(
    target_picks = stringr::str_extract(pic_id, "^\\d{2}") %>% as.numeric()
  )
@
<<bayes-factor-investigation-TargetCloseup, echo = F, fig.width = 7, fig.height = 3.5, fig.cap = sprintf("This graph shows the bayes factor for the target plot in a 20 plot lineup, where the lineup is evaluated by  %d individuals. The bayes factors are truncated at 20 to show the initial exponential increase in bayes factor with increasing target plot selections.", Npicks)>>=
ggplot(data = filter(bf, type == "target") %>% select(-pic_id) %>% unique()) +
  geom_line(aes(x = target_picks, y = pmin(20, bf))) +
  xlab(sprintf("# Target Picks out of %d Total Picks", Npicks)) +
  ylab("Bayes Factor of Target Plot") +
  ggtitle("Change in Bayes Factor of Target Plots with Increasing Signal")
@
<<bayes-factor-investigation-Target, echo = F, fig.width = 7, fig.height = 3.5, fig.cap = sprintf("This graph shows the bayes factor for the target plot in a 20 plot lineup, where the lineup is evaluated by  %d individuals. The y-axis scale is logarithmic because the bayes factor increases approximately exponentially with increasing signal strength.", Npicks)>>=
ggplot(data = filter(bf, type == "target") %>% select(-pic_id) %>% unique()) +
  geom_line(aes(x = target_picks, y = bf)) +
  scale_y_log10() +
  xlab(sprintf("# Target Picks out of %d Total Picks", Npicks)) +
  ylab("Bayes Factor of Target Plot") +
  ggtitle("Change in Bayes Factor of Target Plots with Increasing Signal")
@
<<bayes-factor-investigation-Null, echo = F, fig.width = 7, fig.height = 3.5, fig.cap = sprintf("This graph shows the bayes factors for the null plots in a 20 plot lineup, where the lineup is evaluated by  %d individuals. The Bayes Factors of the null plots decrease with increasing number of target selections.", Npicks)>>=

ggplot(data = filter(bf, type == "null") %>% select(-pic_id) %>% unique()) +
  geom_boxplot(aes(x = factor(target_picks), y = bf)) +
  xlab(sprintf("# Target Picks out of %d Total Picks", Npicks)) +
  ylab("Bayes Factor of Null Plots") +
  ggtitle("Change in Bayes Factor of Null Plots with Increasing Signal")

rm(tmp, bf, bf.sim)
@

\begin{figure}
\begin{subfigure}[b]{.49\textwidth}
\caption{\label{fig:lp-114}Example lineup. }
\includegraphics[width=\textwidth]{lineup-images/e30ff06449a4b7664fe3109f7e2e996f.pdf}
\end{subfigure}
\begin{subfigure}[b]{.49\textwidth}
\caption{\label{fig:posterior2}Posterior densities for the choosing panel \#$i$. }
<<pics2, dependson='posterior', echo=FALSE,  fig.width=8, fig.height = 8, out.width='\\textwidth'>>=

# show one of the results:
i <- 2

lpsXXX <- data.frame(rdirichlet(5000, alpha+turk19.picks$counts[i][[1]]))
lpsXXXm <- melt(lpsXXX, measure.var=1:20)
lpsXXXm$variable <- as.numeric(gsub("X", "", lpsXXXm$variable))

counts <- turk19.picks[i, "counts"][[1]][[1]]
#probs <- turk19.picks[i, "post_prob"][[1]][[1]]
#preprobs <- turk19.picks[i, "pre_prob"][[1]][[1]]
bfactor <- turk19.picks[i, "bfactor"]$bfactor[[1]]$avg
dframe <- data.frame(variable = 1:20, Bfactor= round(bfactor,2))

ymax <- 1:20 %>% lapply(function(i) max(density(subset(lpsXXXm, variable == i)$value)$y)) %>% unlist %>% max

qplot(value, geom="density", data=lpsXXXm, fill=I("grey50"),
      colour=I("grey45"), alpha=I(0.5)) +
  facet_wrap(~variable) + xlim(c(0,1)) +
  theme_bw() +
  xlab("Posterior probability to pick plot") +
  ggtitle(sprintf("Pic ID %s (based on %.1f picks)", turk19.picks$pic_id[i],
                  sum(turk19.picks$counts[i][[1]]))) +
  geom_text(data=dframe, aes(label = Bfactor), x = 1, y = 0.9*ymax, size = 5,
            colour="grey70", hjust="inward", vjust="inward")
@
\end{subfigure}
\caption{\label{fig:xpl-114} Lineup (left) and posterior densities (right) corresponding to evaluations by independent observers.}
\end{figure}

\begin{figure}
\begin{subfigure}[b]{.49\textwidth}
\caption{\label{fig:lp-114}Example lineup. }
\includegraphics[width=\textwidth]{lineup-images/5f9885168e3a02f57ab7216e9f76141d.pdf}
\end{subfigure}
\begin{subfigure}[b]{.49\textwidth}
\caption{\label{fig:posterior2}Posterior densities for the choosing panel \#$i$. }
<<pics3, dependson='posterior', echo=FALSE,  fig.width=8, fig.height = 8, out.width='\\textwidth'>>=
dname <- gsub("-turk16","", subset(pics19, pic_id == 104)$data_name)
dname <- gsub("sd\\.","sd", dname)
dname <- gsub("trend", "line", dname)

samedata <- subset(pics16, data_name == dname)
# subset(samedata, test_param == "turk16-colorEllipse")
# identifies 5f9885168e3a02f57ab7216e9f76141d

# show one of the results:
i <- subset(samedata, test_param == "turk16-colorEllipse")$pic_id

lpsXXX <- data.frame(rdirichlet(5000, alpha+turk16.picks$counts[i][[1]]))
lpsXXXm <- melt(lpsXXX, measure.var=1:20)
lpsXXXm$variable <- as.numeric(gsub("X", "", lpsXXXm$variable))

counts <- turk16.picks[i, "counts"][[1]][[1]]
#probs <- turk16.picks[i, "post_prob"][[1]][[1]]
#preprobs <- turk16.picks[i, "pre_prob"][[1]][[1]]
bfactor <- turk16.picks[i, "bfactor"]$bfactor[[1]]$avg
dframe <- data.frame(variable = 1:20, Bfactor= round(bfactor,2))

ymax <- 1:20 %>% lapply(function(i) max(density(subset(lpsXXXm, variable == i)$value)$y)) %>% unlist %>% max

qplot(value, geom="density", data=lpsXXXm, fill=I("grey50"),
      colour=I("grey45"), alpha=I(0.5)) +
  facet_wrap(~variable) + xlim(c(0,1)) +
  theme_bw() +
  xlab("Posterior probability to pick plot") +
  ggtitle(sprintf("Pic ID %s (based on %.1f picks)", turk16.picks$pic_id[i],
                  sum(turk16.picks$counts[i][[1]]))) +
  geom_text(data=dframe, aes(label = Bfactor), x = 1, y = 0.9*ymax, size = 5,
            colour="grey70", hjust="inward", vjust="inward")

@
\end{subfigure}
\caption{\label{fig:xpl-124} Lineup (left) and posterior densities (right) corresponding to evaluations by independent observers.}
\end{figure}

\hh{can we combine multiple lineups?}
\svp{You mean compare which plots are most likely to be selected out of several sets of sub-plots? That's an interesting idea, but I'm not sure that there's an obvious way to do that... Unless you just ``integrate" over multiple lineups and selections? That can't be valid, can it?}

\hh{XXX Bayesian equivalent of a logistic regression with random effects, jags? }
\bibliographystyle{asa}
\bibliography{references}

\end{document}
