\documentclass[12pt]{article}
% \usepackage{geometry}                % See geometry.pdf to learn the layout options. There are lots.
% \geometry{letterpaper}                   % ... or a4paper or a5paper or ...
%\usepackage{graphicx}
\usepackage[font=small,skip=5pt]{caption}
\usepackage{subcaption}
\usepackage{afterpage}
\usepackage{amssymb}
\usepackage{natbib}
\usepackage{amsmath}
\usepackage{amsfonts}
% \usepackage{color}
\usepackage{multirow}
\usepackage{rotating}
\usepackage[dvipsnames,svgnames,table]{xcolor}
\usepackage{hyperref}
\graphicspath{{figure/}}
% \usepackage{endfloat} % Figures to the end of the document

\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png}
%---------------------------------------------------
%                 Editing Commands
%\newcommand{\hh}[1]{{\color{magenta} #1}}
%\newcommand{\svp}[1]{{\color{orange} #1}}
\newcommand{\eh}[1]{{\color{cyan} #1}}

\usepackage[colorinlistoftodos]{todonotes}
%                 Editing Commands
\newcommand{\done}[2][inline]{\todo[color=SpringGreen, #1]{#2}}  % for todos that have been seen and dealt with
\newcommand{\meh}[2][inline]{\todo[color=White, #1]{#2}}   % for todos that may no longer be relevant
\newcommand{\comment}[2][inline]{\todo[color=SkyBlue, #1]{#2}} % for comments that may not be "to-do"s
\newcommand{\newtext}[1]{\todo[inline, color=White]{ \color{OliveGreen}{#1}}} % new text - not necessarily something to be done
\newcommand{\newdo}[1]{\todo[inline, color=Lime]{#1}} % new to do item
\newcommand{\hh}[2][inline]{\todo[color=magenta,#1]{#2}}
\newcommand{\svp}[2][inline]{\todo[color=orange,#1]{#2}}


%---------------------------------------------------
%                 Placing Figures


%---------------------------------------------------
% Define new environment
\newtheorem{theorem}{Theorem}[section]
\newtheorem{algorithm}[theorem]{Algorithm}
%---------------------------------------------------

%\pdfminorversion=4
% NOTE: To produce blinded version, replace "0" with "1" below.
\newcommand{\blind}{0}

% DON'T change margins - should be 1 inch all around.
\addtolength{\oddsidemargin}{-.5in}%
\addtolength{\evensidemargin}{-.5in}%
\addtolength{\textwidth}{1in}%
\addtolength{\textheight}{1.3in}%
\addtolength{\topmargin}{-.8in}%


\begin{document}

%\bibliographystyle{natbib}

\def\spacingset#1{\renewcommand{\baselinestretch}%
{#1}\small\normalsize} \spacingset{1}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\if0\blind
{
  \title{\bf A Bayesian approach to visual inference}
  \author{Susan VanderPlas, Eric Hare\thanks{
    The authors gratefully acknowledge funding from the National Science Foundation Grant \# DMS 1007697. All data collection has been conducted with approval from the Institutional Review Board IRB 10-347}\hspace{.2cm}\\
    Department of Statistics and Statistical Laboratory, Iowa State University\\
    and \\
    Heike Hofmann\\
    Department of Statistics and Statistical Laboratory, Iowa State University}
  \maketitle
} \fi

\if1\blind
{
  \bigskip
  \bigskip
  \bigskip
  \begin{center}
    {\LARGE\bf A Bayesian approach to visual inference}
\end{center}
  \medskip
} \fi

\bigskip
\begin{abstract}
Graphics play a crucial role in statistical analysis and data mining. The lineup protocol for experimentally testing graphics has traditionally used p-values to identify plots which are significantly visually distinct from distractor plots, but this approach does not easily translate to examining randomly generated plots to determine the strength of the distractor effect. This study presents a bayesian approach to visual inference, using bayes factors to examine the difference in signal strength in two-target statistical lineups.
\end{abstract}

\noindent%
{\it Keywords:}  Visual inference, Lineup protocol, \hh{XXX Other keywords?}.
\vfill

\newpage
\spacingset{1.45} % DON'T change the spacing!

\tableofcontents
\newpage

<<setup, echo = FALSE, message = FALSE, warning = FALSE>>=
options(replace.assign=TRUE,width=70, digits=2)
require(knitr)
opts_chunk$set(fig.path='figure/', cache.path='cache/', fig.align='center', fig.width=5, fig.height=5, par=TRUE, cache=TRUE, concordance=TRUE, autodep=TRUE, message=F, warning=F)

library(dplyr)
library(tidyr)
library(purrr)
@

\section{Introduction}
Graphics are an important component of big data analysis, providing a mechanism for discovering unexpected patterns in data. Pioneering research by \citet{gelman:2004}, \citet{buja:2009} and \citet{majumder:2011} provide methods to quantify the significance of discoveries made from visualizations.
%Although, there have been major advances in statistical graphics over the years, for example, systems like R \citep{R} provide high quality static graphics, and very recently some access to interactive graphics. But the problem remains that graphics are not widely considered to be a part of inferential statistics.
\citet{buja:2009} introduced two protocols, the Rorschach and the lineup protocol, which bridge the gulf between traditional statistical inference and exploratory data analysis. The Rorschach protocol consists of a set of $m$ (usually, $m=20$) plots (called the {\it null plots}) rendered from data that is consistent with a given null model. That way, the Rorschach protocol helps to understand the extent of randomness in the null model. Under the lineup protocol, a plot of the observed data is placed randomly among a set of $m-1$ null plots.
Human observers are then asked to  examine the lineup and to identify the most different plot. If observers identify the data plot, this is quantifiable evidence against the null hypothesis.
The lineup protocol places a statistical plot firmly in the framework of hypothesis tests: a plot of the data is considered to be the test statistic, which is compared against the sampling distribution under the null hypothesis represented by the null plots.
Obviously, the null generating mechanism, i.e.\ the method of obtaining the data for null plots, is crucial for both the lineup and the Rorschach protocol.
The null hypothesis directly affects the choice of null generating method.
Null generating methods are typically based on (a) simulation, if the null hypothesis allows us to directly specify a parametric model, (b) sampling, as for example in the case of large data sets, or (c) permutation of the original data \citep[see e.g.\ ][]{Good05}, which allows for non-parametric testing  that preserves marginal distributions  while ensuring independence in higher dimensions.
%In the experimental data that we analyzed the null generating methods used were permutation methods and direct simulation from a null model.

The lineup protocol was formally tested in a head-to-head comparison with the equivalent conventional test in \citet{majumder:2011}. The experiment utilized human subjects from Amazon's Mechanical Turk \citep{turk} and used simulation to control conditions. The results suggest that  visual inference is comparable to conventional tests in a controlled conventional setting. This provides support for its appropriateness for testing in real exploratory situations where no conventional test exists. Interestingly, the power of a visual test increases with the number of observers engaged to evaluate lineups, and the pattern in results suggests that the power will provide results consistent with practical significance \citep{kirk:1996}.

\comment{Should cite Adam's papers that examined some null plots as well. Could even possibly analyze some of that data later on as a proof of concept.}
\svp{Which paper...? I've skimmed several of them and can't seem to find one that talks about the 100\% null plot lineups.}

\subsection{Analysis of Statistical Lineups}
Statistical lineups typically consist of 20 plots which are then evaluated by $K$ individuals. Conceptually, if most individuals are able to identify a single target plot surrounded by 19 null plots, this would correspond to a statistical test which is significant at the $p < 0.05$ level. Calculation of the visual p-value is a bit more complicated in reality, as discussed in \citet{majumder2013validation}. For a lineup of size $m$ (usually 20), the probability that at least $x$ observers select the target plot is
\begin{eqnarray}
P(X \geq x) &= 1 - \text{Binom}_{K, 1/m}(x-1)\\
& = \sum_{i=1}^K\binom{K}{i} \left(\frac{1}{m}\right)^i\left(\frac{m-1}{m})^{K-i}
\end{eqnarray}

When lineups contain two targets, slight tweaks are made to the underlying probability distribution\citep[Appendix B]{vanderplas:2017}, and the resulting p-value must be obtained by simulation. There is a less natural interpretation of the p-values resulting from a two-target lineup, as there are two competing alternative hypotheses in this scenario. A much more natural approach to the two-target lineup is to consider the evidence for each of two hypotheses relative to the null hypothesis using a Bayesian approach.


\section{A Bayesian's Statistical Lineup}
Let $p_i$, $i = 1, ..., m$ be the probability that plot $i$ is picked out of a lineup of $m$ panels. We know that $0 \le p_i \le 1$ with $\sum_{i=1}^m p_i = 1$.

We can assign an uninformative prior probability to $p$ by using a Dirichlet distribution (a single-parameter distribution over the $(m-1)$ simplex, with identical marginals for each plot $i$). An uninformative prior is desireable because a priori we assume that the plots are all equally likely to be selected by a participant.

We will use the following model:
\begin{eqnarray*}
\alpha &=& (\alpha_1, \alpha_2, ..., \alpha_m) = \text{concentration hyperparameter}\\
p \mid \alpha &=& (p_1, p_2, ..., p_m) \sim Dir (m, \alpha) \\
c \mid p &=& (c_1, c_2, ..., c_m) \sim Mult (m, p)
\end{eqnarray*}

Figure \ref{fig:prior} shows the prior distribution for each lineup panel.

The posterior distribution is then as follows:
\begin{eqnarray*}
c &=& (c_1, ..., c_m) = \text{ number of picks of each plot} \\
K &=& \text{ Total number of evaluations} = \sum_{i=1}^m c_i\\
p \mid c, \alpha &\sim& Dir (K, \alpha_1+c_1, \alpha_2+c_2, ..., \alpha_m + c_m)
\end{eqnarray*}

% \svp{Need to adjust notation to account for multiple plot selections somehow. Maybe add that extension below? e.g. let $z_{ij}$ represent the selection of plot $i$ as the $j$th plot selected. Then $p_i$ = $\sum_{j = 1}^{20} z_{ij}/\sum_{j = 1}^{20} (z_{ij} \text{ is not null})$ or something?}

Visual inference usually utilizes a null hypothesis of the form `the plot of the data is not in any way different from the null plots'.  Under this null hypothesis the vector of concentration parameters $\alpha$ has to consist of the same values, i.e.\ $\alpha_i = $const. The sum of the concentration parameters $\sum{\alpha}$ can be interpreted as the number of (pseudo)evaluations  under the null hypothesis. Jeffreys' uninformative prior \citep{jeffreys:1946} for this situation is $\alpha = \frac{1}{2}$, corresponding to 10 pseudo-evaluations.

% \hh{this is likely a parameter we have to fine-tune, right now it is set to be $\alpha = 1/2$.
% For $\alpha = 1$ we need a lot of data (in form of evaluations by observers) in order to get the posterior distribution away from the prior, even if we have a strong signal.}

One of the advantages of this model is that it allows a seamless incorporation of results from multiple picks by using reciprocal weights: if an evaluator identified three panels as the `most different', each of these three panels gets an additional $1/3$ to its overall number of picks $c$.

\begin{figure}
\centering
<<prior, echo=FALSE, fig.width = 8, fig.height = 8, out.width='0.7\\textwidth'>>=
library(gtools)
# library(reshape2)
library(tidyr)
library(ggplot2)

m <- 20
alpha <- rep(1/2, m)
alpha_2 <- rep(20, m)
lps <- data.frame(rdirichlet(5000, alpha))

lpsm <- gather(lps, key = "variable")
lpsm$variable <- as.numeric(gsub("X", "", lpsm$variable))

qplot(value, geom="density", data=lpsm, fill=I("grey50"),
      colour=I("grey45"), alpha=I(0.5)) +
  facet_wrap(~variable) + xlim(c(0,1)) +
  theme_bw() +
  xlab("Probability to pick plot")
@
\caption{\label{fig:prior}Jeffreys' noninformative prior for any lineup of size 20. }
\end{figure}

<<posterior, echo=FALSE, cache = TRUE, warning=FALSE, message=FALSE>>=
getCounts <- function(response) {
  results <- strsplit(response,split=",")
  wt <- sapply(results, length)
  wt <- 1/rep(wt, wt)
  picks <- factor(as.numeric(unlist(results)), levels=1:20)

  counts <- xtabs(wt~picks)
  as.vector(counts)
}

bfactors <- function(a1, a2, counts) {
  x <- seq(0,1, by=0.001)
  bf <- lapply(1:20, function(i) {
    # m2 <- pbeta(x, shape1 = a2[i] + counts,
    #             shape2 = sum(a2) - a2[i] + sum(counts) - counts[i],
    #             lower.tail=FALSE)
    # m1 <- pbeta(x, shape1=a1[i] + counts[i],
    #             shape2 = sum(a1) - a1[i] + sum(counts) - counts[i],
    #             lower.tail=FALSE)
    # sum(m1)/sum(m2)

    beta(a2[i], sum(a2) - a2[i])/beta(a1[i], sum(a1) - a1[i]) *
      beta(counts[i] + a1[i], sum(counts) - counts[i] + sum(a1) - a1[i])/
      beta(counts[i] + a2[i], sum(counts) - counts[i] + sum(a2) - a2[i])
  })
  # This version sums first and then divides.

  # now get averages
  # bfavg <- bf %>% lapply(sum) %>% unlist
  # bfmode <- bf %>% lapply(max) %>% unlist

  bf
}

pre_post_picks <- function(data) {
  # needs to have a picture id
  data.picks <- data %>% group_by(pic_id) %>% do(
    counts = getCounts(.$response_no))
  data.picks <- data.picks %>% group_by(pic_id) %>% mutate(
    picks = sum(counts[[1]]),
    post_mean = list((alpha + counts[[1]])/sum(alpha + counts[[1]])),
    post_mode = list((alpha + counts[[1]] - 1)/sum(alpha + counts[[1]]-1)),
    bfactor = list(bfactors(alpha, alpha_2, counts[[1]])),
    pre_prob  = list(pbeta(1/20*2, shape1=alpha, shape2=sum(alpha)-alpha,
                           lower.tail=FALSE)),
    post_prob = list(pbeta(1/20*2, shape1=alpha+counts[[1]],
                           shape2=sum(alpha)-alpha + sum(counts[[1]]) - counts[[1]],
                           lower.tail=FALSE))
  )
  data.picks
}

turk19 <- read.csv("data/turk19_results_anon.csv", stringsAsFactors = FALSE)
turk16 <- read.csv("data/turk16_results.csv", stringsAsFactors = FALSE)
turk1013 <- read.csv("data/turk1013_results.csv", stringsAsFactors = FALSE)

pics19 <- read.csv("data/picture-details-turk19.csv", stringsAsFactors = FALSE)
pics16 <- read.csv("data/picture-details-turk16.csv", stringsAsFactors = FALSE)
pics10 <- read.csv("data/picture-details-turk10.csv", stringsAsFactors = FALSE)

turk19.picks <- pre_post_picks(turk19)
turk16.picks <- pre_post_picks(turk16)
turk1013.picks <- pre_post_picks(turk1013)
@

\begin{figure}
\begin{subfigure}[b]{.49\textwidth}
\caption{\label{fig:lp-104}Example lineup. }
\includegraphics[width=\textwidth]{lineup-images/filebab6558ba4c4-multiple.pdf}
\end{subfigure}
\begin{subfigure}[b]{.49\textwidth}
\caption{\label{fig:posterior}Posterior densities for the choosing panel \#$i$. }
<<pics-turk1013, dependson='posterior', echo=FALSE,  fig.width=8, fig.height = 8, out.width='\\textwidth'>>=
# show one of the results:
i <- 1

lpsXXX <- data.frame(rdirichlet(5000, alpha+turk1013.picks$counts[i][[1]]))
lpsXXXm <- gather(lpsXXX, key = "variable")
lpsXXXm$variable <- as.numeric(gsub("X", "", lpsXXXm$variable))

counts <- turk1013.picks[i, "counts"][[1]][[1]]
#probs <- turk1013.picks[i, "post_prob"][[1]][[1]]
#preprobs <- turk1013.picks[i, "pre_prob"][[1]][[1]]
# bfactor <- turk1013.picks[i, "bfactor"]$bfactor[[1]]$avg
bfactor <- turk1013.picks[i, "bfactor"]$bfactor[[1]] %>% unlist()
dframe <- data.frame(variable = 1:20, Bfactor= round(bfactor,2))

ymax <- 1:20 %>% lapply(function(i) max(density(subset(lpsXXXm, variable == i)$value)$y)) %>% unlist %>% max

qplot(value, geom="density", data=lpsXXXm, fill=I("grey50"),
      colour=I("grey45"), alpha=I(0.5)) +
  facet_wrap(~variable) + xlim(c(0,1)) +
  theme_bw() +
  xlab("Posterior probability to pick plot") +
  ggtitle(sprintf("Pic ID %s (based on %.1f picks)", turk1013.picks$pic_id[i],
                  sum(turk1013.picks$counts[i][[1]]))) +
  geom_text(data=dframe, aes(label = Bfactor), x = 1, y = 0.95*ymax, size = 5,
            colour="grey70", hjust="inward", vjust="inward")

@
\end{subfigure}
\caption{\label{fig:xpl-turk1013} Lineup (left) and posterior densities (right) corresponding to evaluations by independent observers.}
\end{figure}
Figure \ref{fig:xpl-turk1013} shows a lineup and the corresponding posterior densities of the lineup after evaluation by \Sexpr{sum(turk1013.picks[i, "counts"][[1]][[1]])} independent observers. Plots 4 and 14 appear to have attracted the attention of most of the observers; one individual identified plot 10 instead.

\begin{figure}
\begin{subfigure}[b]{.49\textwidth}
\caption{\label{fig:lp-104}Example lineup. }
\includegraphics[width=\textwidth]{lineup-images/34fcf946135adb1c03b147897f20b33d.pdf}
\end{subfigure}
\begin{subfigure}[b]{.49\textwidth}
\caption{\label{fig:posterior}Posterior densities for the choosing panel \#$i$. }
<<pics, dependson='posterior', echo=FALSE,  fig.width=8, fig.height = 8, out.width='\\textwidth'>>=

# show one of the results:
i <- 1

lpsXXX <- data.frame(rdirichlet(5000, alpha+turk19.picks$counts[i][[1]]))
lpsXXXm <- gather(lpsXXX, key = "variable")
lpsXXXm$variable <- as.numeric(gsub("X", "", lpsXXXm$variable))

counts <- turk19.picks[i, "counts"][[1]][[1]]
probs <- turk19.picks[i, "post_prob"][[1]][[1]]
preprobs <- turk19.picks[i, "pre_prob"][[1]][[1]]
# bfactor <- turk19.picks[i, "bfactor"]$bfactor[[1]]$avg
bfactor <- turk19.picks[i, "bfactor"]$bfactor[[1]] %>% unlist()
bfs <- turk19.picks[i, "bfactor"]$bfactor[[1]]$factor
dframe <- data.frame(variable = 1:20, Bfactor= round(bfactor,2))

ymax <- 1:20 %>% lapply(function(i) max(density(subset(lpsXXXm, variable == i)$value)$y)) %>% unlist %>% max

qplot(value, geom="density", data=lpsXXXm, fill=I("grey50"),
      colour=I("grey45"), alpha=I(0.5)) +
  facet_wrap(~variable) + xlim(c(0,1)) +
  theme_bw() +
  xlab("Posterior probability to pick plot") +
  ggtitle(sprintf("Pic ID %s (based on %.1f picks)", turk19.picks$pic_id[i],
                  sum(turk19.picks$counts[i][[1]]))) +
  geom_text(data=dframe, aes(label = Bfactor), x = 1, y = 0.9*ymax, size = 5,
            colour="grey70", hjust="inward", vjust="inward")

@
\end{subfigure}
\caption{\label{fig:xpl-104} Lineup (left) and posterior densities (right) corresponding to evaluations by independent observers.}
\end{figure}

For each individual panel of the lineup, the marginal distributions are Beta distributions. For the distribution of picking panel $i$ the prior distribution is therefore a Beta distribution Beta$(1, 19)$. In the example of Figure~\ref{fig:posterior} we have a Beta distribution of Beta$(\Sexpr{counts[11]+ alpha[11]}, \Sexpr{sum(alpha)+sum(counts)-counts[11]-alpha[11]})$ for panel \#11 and Beta$(\Sexpr{counts[20]+ alpha[20]}, \Sexpr{sum(alpha)+sum(counts)-counts[20]-alpha[20]})$ for panel \#20.


\paragraph{Calculation of the Bayes factor for plot \#$i$}\hfill\newline
In order to assess the strength of the signal of plot \#$i$, we calculate the Bayes Factor, which assesses the posterior odds of the full model described above relative to a model which has uniform probability of selecting each plot. These Bayes factors are calculated using the marginal distribution which compares each single plot to the collective "other"; the marginal distributions reduce to a Beta-Binomial model. More formally,
\begin{align}
M_1 & :=  \text{Beta-Binomial model with Jeffrey's prior}\nonumber\\
M_2 & :=  \text{Beta-Binomial model with strong prior, mass around }\alpha = 0.05\nonumber\\
BF & =  P(M_1|c)/P(M_2|c)\\
& =  \frac{\int_{p} P(M_1) f_1(c|p) \pi(p) dp}{\int_p P(M_2) f_2(c|p)\pi(p) dp}\nonumber
\end{align}
We will set the prior odds of $M_1$ to be equal to the prior odds of $M_2$, that is, $P(M_1) = P(M_2)$.

What remains is to set the parameters for model 2 so that the strong prior belief that all plots are equally likely to be selected is reflected in the model. We decided to use a Dirichlet distribution with extremely large $\alpha$ = 20, which would be the equivalent of pre-specifying 20 selections of each sub-plot. This distribution has marginal distributions equivalent to the Beta(20, 380) distribution, which has a mean of 0.05 and standard deviation of \Sexpr{round(sqrt((20*380)/(400^2*401)), 3)}.

\begin{figure}
\centering
<<prior-model2, echo=FALSE, fig.width = 8, fig.height = 8, out.width='0.7\\textwidth'>>=
m <- 20
lps <- data.frame(rdirichlet(5000, alpha_2))

lpsm <- gather(lps, key = "variable")
lpsm$variable <- as.numeric(gsub("X", "", lpsm$variable))

qplot(value, geom="density", data=lpsm, fill=I("grey50"),
      colour=I("grey45"), alpha=I(0.5)) +
  facet_wrap(~variable) + xlim(c(0,1)) +
  theme_bw() +
  xlab("Probability to pick plot")
@
\caption{\label{fig:prior-model2}A strongly informative prior for any lineup of size 20 which reflects the belief that all sub-plots are equally likely to be selected. }
\end{figure}

With both M1 and M2 specified, we can calculate an explicit formula for the bayes factor for a specific panel $i$, where $c_i$ is the number of picks of the panel, $K$ is the total number of evaluations of the lineup overall, $\pi_1(p) \sim \text{Beta}(1/2, 1/2)$, $\pi_2(p) \sim \text{Beta}(20, 380)$, and $f(c_i, K | p) \sim \text{Binomial}(K, p)$.
\begin{align}
BF(M_1, M_2) & = \frac{\int_p P(M_1) f(c_i, K|p) \pi_1(p) dp}{\int_p P(M_2) f(c_i, K|p) \pi_2(p)}\nonumber\\
& = \frac{P(M_1)}{P(M_2)}
    \frac{\int_p \binom{K}{c_i} p^{c_i}(1-p)^{K - c_i} \cdot \frac{1}{B(\frac{1}{2}, \frac{19}{2})} p^{-\frac{1}{2}}(1-p)^{-\frac{17}{2}}}
         {\int_p \binom{K}{c_i} p^{c_i}(1-p)^{K - c_i} \cdot \frac{1}{B(20, 380)} p^{19}(1-p)^{379}}\nonumber\\
& = \frac{\binom{K}{c_i}}{\binom{K}{c_i}}
    \frac{B(20, 380)}{B(\frac{1}{2}, \frac{19}{2})}
    \frac{\int_p p^{c_i - \frac{1}{2}}(1-p)^{K - c_i + \frac{17}{2}}}
         {\int_p p^{c_i + 19}(1-p)^{K - c_i + 379}} \nonumber\\
& = \frac{B(20, 380)}{B(\frac{1}{2}, \frac{19}{2})}
    \frac{B(c_i + \frac{1}{2}, K - c_i + \frac{19}{2}) \int_p \frac{1}{B(c_i + \frac{1}{2}, K - c_i + \frac{19}{2})} p^{c_i - \frac{1}{2}}(1-p)^{K - c_i + \frac{17}{2}}}
         {B(c_i + 20, K - c_i + 380) \int_p \frac{1}{B(c_i + 20, K - c_i + 380)} p^{c_i + 19}(1-p)^{K - c_i + 379}} \nonumber\\
& = \frac{B(20, 380)}{B(\frac{1}{2}, \frac{19}{2})}
    \frac{B(c_i + \frac{1}{2}, K - c_i + \frac{19}{2})}{B(c_i + 20, K - c_i + 380)}
    \frac{\int_p \frac{1}{B(\alpha_1, B_1)} p^{\alpha_1 - 1}(1-p)^{B_1 - 1}}
         {\int_p \frac{1}{B(\alpha_2, B_2)} p^{\alpha_2 - 1}(1-p)^{B_2 - 1}} \nonumber\\
&\phantom{ = } \text{ where }\alpha_1 = c_i + \frac{1}{2}, B_1 = K - c_i + \frac{19}{2}, \alpha_2 = c_i + 20, B_2 = K - c_i + 380 \nonumber\\
& = \frac{B(20, 380)}{B(\frac{1}{2}, \frac{19}{2})}
    \frac{B(c_i + \frac{1}{2}, K - c_i + \frac{19}{2})}{B(c_i + 20, K - c_i + 380)}
\end{align}

% This calculation allows us to not only assess the strength of the observers' preference for each panel relative to the uniform probability model; in a two-target lineup, the bayes factors for each target plot can be used to calculate a bayes factor which assesses the strength of the two competing alternative hypotheses. If we consider the marginal distribution for each target plot individually, we calculate separate bayes factors for each target plot.
%
% \begin{align}
% M_{11} & :=  \text{Beta-Binomial model with Jeffrey's prior, for target plot 1}\nonumber\\
% M_{12} & :=  \text{Beta-Binomial model with Jeffrey's prior, for target plot 2}\nonumber\\
% M_2 & :=  \text{Beta model (equivalent to Jeffrey's prior)}\nonumber\\
% BF_1 & =  P(M_{11}|c)/P(M_2|c)\nonumber\\
% & =  \frac{\int_{p} P(M_{11}) f_1(c|p) \pi(p) dp}{\int_p P(M_2) f_2(c|p)\pi(p) dp}\nonumber\\
% BF_2 & =  P(M_{12}|c)/P(M_2|c)\nonumber\\
% & =  \frac{\int_{p} P(M_{12}) f_1(c|p) \pi(p) dp}{\int_p P(M_2) f_2(c|p)\pi(p) dp}\nonumber\\
% BF_{1,2} & =  BF_1/BF_2\\
% & =  \frac{\int_{p} P(M_{11}) f_1(c|p) \pi(p) dp/ \int_p P(M_2) f_2(c|p)\pi(p) dp}{\int_{p} P(M_{12}) f_1(c|p) \pi(p) dp / \int_p P(M_2) f_2(c|p)\pi(p) dp}\nonumber
% & =  \frac{\int_{p} P(M_{11}) f_1(c|p) \pi(p) dp}{\int_{p} P(M_{12}) f_1(c|p) \pi(p) dp}\nonumber
% \end{align}

%
% \svp{We need to explain the cutoff threshold a bit more - develop the ``why".}
% \hh{XXX after discussion with Susan: put a prior uniform on the cutoff threshold $t$ - either integrate it out or find a mode in the posterior.}
% \hh{XXX  integration seems to work out really well - what do you think? }
%
% In order to assess the strength of the signal of plot \#$i$, we assess the probability that an observer chooses this plot at a pre-specified level $t$ and compare the posterior probability to its prior for a Bayes factor.
% More formally, we define the Bayes factor of choosing plot \#$i$ given threshold level $t$ as
% \[
% B_t(p_i) = \frac{P(p_i > t \mid x, \alpha)}{P(p_i > t \mid \alpha)},
% \]
% where $t$ is a pre-specified threshold with $t \in (0,1)$ and $p_i$ is the probability that an observer chooses plot \#$i$, $1 \le i \le m$, as the most different.
% \svp{``most different" is a bit of a weird phrase given that we're allowing participants to select multiple panels. Perhaps ``observer selects plot ... as visually distinct"?}
%
% \svp{Is this thing $B_t$ technically a bayes factor any more? I would think so, but I'm not sure...?\\Upon further reflection, for a single value of $t$ it's a Bayes factor over a reduced sample space, I believe. However, it doesn't make that much sense to integrate $t$ out if that's the interpretation; rather, just integrate over the entire parameter space $[0,1]$ instead.}
%
% The choice of $t$ is critical: a natural choice would be $t = 1/m$, where $m$ is the size of the lineup. However, the prior probability in a lineup of size 20 is $\Sexpr{round(pbeta(1/20, shape1=alpha[1], shape2=sum(alpha)-alpha[1], lower.tail=FALSE), 3)}$ when using the uninformative prior described above. This puts an upper limit on the Bayes factor of $\Sexpr{round(1/pbeta(1/20, shape1=alpha[1], shape2=sum(alpha)-alpha[1], lower.tail=FALSE), 2)}$ (the reciprocal value of the prior). A higher threshold allows for a higher upper limit on the Bayes factor, e.g.\ a threshold of $t = \frac{2}{m}$ already allows for a Bayes factor of up to \Sexpr{round(1/pbeta(1/20*2, shape1=alpha[1], shape2=sum(alpha)-alpha[1], lower.tail=FALSE),2)}. For the example shown in Figure~\ref{fig:xpl-104}, the posterior probabilities of picking panels \#11 and \#20 with a probability of at least $t = \frac{2}{m}$ are \Sexpr{round(probs[11],4)} and \Sexpr{round(probs[20],4)}, respectively. This corresponds to Bayes factors of  \Sexpr{round(probs[11]/preprobs[11],2)} and \Sexpr{round(probs[20]/preprobs[20],2)}.
% An overview of the Bayes factors $B_t$ for a specific lineup is shown in Figure~\ref{fig:bt-104}.
%
% \begin{figure}
% \begin{subfigure}[b]{.49\textwidth}
% \caption{\label{fig:lp-104-bt}Example lineup. }
% \includegraphics[width=\textwidth]{lineup-images/34fcf946135adb1c03b147897f20b33d.pdf}
% \end{subfigure}
% \begin{subfigure}[b]{.49\textwidth}
% \caption{\label{fig:bfactor}Bayes factors at each value of $t \in (0,1)$. }
% <<Bfactort, echo=FALSE, fig.width=7, fig.height=7>>=
% x <- seq(0,0.9999, by=0.01)
% BFS <- 1:20 %>% lapply(function(i) data.frame(i, x = x, bf=bfs[[i]])) %>% bind_rows
% BFS$capbf <- pmin(BFS$bf, 20)
% qplot(x, capbf,  geom="line", data= BFS) + theme_bw() +
%   facet_wrap(facets = ~i) +
%   ylab("Bayes factor at threshold t") +
%   xlab("Threshold t") #+ ylim(c(0,20))
% @
% \end{subfigure}
% \caption{\label{fig:bt-104} Lineup (left) and Bayes factors at threshold $t$ (right). Note that the Bayes factors for plot \#20 are capped at a value of 20. Uncapped, the Bayes factor for \#20 reaches a mode of over 300. }
% \end{figure}
%
% Instead of deciding for a single value of $t$,
% we integrate over all possible values of $t$ and get the Bayes factor for plot \#$i$ as:
% \[
% B(p_i) = \int_0^1 B_t(p_i) dt = \int_0^1 \frac{P(p_i > t \mid x, \alpha)}{P(p_i > t \mid \alpha)} dt.
% \]

There are different schemes interpreting the Bayes factor. \citet{jeffreys:1961} consider a factor of 5 to 10 as `substantial', and values above 20 as `decisive'.
Alternatively, \citet{kass:1995} consider a factor of 6 to 10 as `strong', and values above 10 as `very strong'.
\FloatBarrier
\hh{XXX investigate Bayes factor of different scenarios, ie ten evaluations, different number of data picks and null picks. How does that compare to the visual distribution $V_3$? (the Binomial like distribution that is adjusted for dependencies between the data and the nulls). }
<<bayes-factor-investigation-params, echo = F>>=
Nruns <- 100
Npicks <- 20
@
We simulated bayes factors arising from the following scenario: Out of \Sexpr{Npicks} evaluations, the target plot was selected $x$ times (null plot selections were randomly generated with $\Sexpr{Npicks}-x$ total selections of null plots). For each value of $x$, this simulation was run \Sexpr{Nruns} times, and the results are shown in Figure \ref{fig:bayes-factor-investigation-Target} (target plot bayes factors) and Figure \ref{fig:bayes-factor-investigation-Null} (null plot bayes factors). The target plot bayes factors were identical across all \Sexpr{Nruns} simulation runs, but the null plot bayes factors were not, as a result, the target bayes factor plot consists of a single line while the null bayes factor plot shows a series of boxplots representing the distribution of bayes factors for each of 19 null plots in each of \Sexpr{Nruns} simulation runs with $x$ between 0 and \Sexpr{Npicks}. The bayes factor for the target plot initially decreases with increasing selections (corresponding to approximately ``uniform" distribution of plot picks) and then increases dramatically with each increasing selection of the target plot.

<<bayes-factor-investigation, echo = F>>=
# Investigate Bayes factor of different scenarios, i.e. 10 evaluations with different number of data picks and null picks.
library(purrr)
# Plot 1 = data plot
bf.sim <- 0:Npicks %>%
  map_df(.f = function(i) {
    1:Nruns %>%
      map_df(.f = function(j){
        data.frame(
          pic_id = sprintf("%02d.%02d", i, j),
          response_no = as.character(c(rep(1, i), sample(2:20, size = (Npicks - i), replace = T))))
      })
  })
tmp <- pre_post_picks(bf.sim)
tmp %<>%
  mutate(data.picks = stringr::str_extract(pic_id, "^\\d{1,}") %>%
           as.numeric) %>%
  arrange(data.picks)

# Get bayes factors for signal and null plots out
bf <- 1:nrow(tmp) %>%
  map_df(.f = function(i) {
    x <- tmp[i,]
    data_frame(
      pic_id = x[["pic_id"]],
      type = c("target", rep("null", 19)),
      bf = unlist(x$bfactor[[1]]))
  }) %>%
  mutate(
    target_picks = stringr::str_extract(pic_id, "^\\d{2}") %>% as.numeric()
  )
@

<<bayes-factor-investigation-Target-trunc, echo = F, fig.width = 7, fig.height = 3.5, fig.cap = sprintf("This graph shows the bayes factor for the target plot in a 20 plot lineup, where the lineup is evaluated by  %d individuals, but is truncated at BF = 20, which corresponds to overwhelming evidence.", Npicks)>>=
ggplot(data = filter(bf, type == "target") %>% select(-pic_id) %>% unique()) +
  geom_line(aes(x = target_picks, y = pmin(20, bf))) +
  xlab(sprintf("# Target Picks out of %d Total Picks", Npicks)) +
  ylab("Bayes Factor of Target Plot") +
  ggtitle("Change in Bayes Factor of Target Plots with Increasing Signal")
@

<<bayes-factor-investigation-Target, echo = F, fig.width = 7, fig.height = 3.5, fig.cap = sprintf("This graph shows the bayes factor for the target plot in a 20 plot lineup, where the lineup is evaluated by  %d individuals.", Npicks)>>=
ggplot(data = filter(bf, type == "target") %>% select(-pic_id) %>% unique()) +
  geom_line(aes(x = target_picks, y = bf)) +
  xlab(sprintf("# Target Picks out of %d Total Picks", Npicks)) +
  scale_y_log10("Bayes Factor of Target Plot") +
  ggtitle("Change in Bayes Factor of Target Plots with Increasing Signal")
@

<<bayes-factor-investigation-Null, echo = F, fig.width = 7, fig.height = 3.5, fig.cap = sprintf("This graph shows the bayes factors for the null plots in a 20 plot lineup, where the lineup is evaluated by  %d individuals. The Bayes Factors of the null plots are more variable when target selections are low, but converge to about 1.5 as the number of target picks increase.", Npicks)>>=
#
# ggplot(data = filter(bf, type == "null")) +
#   geom_jitter(aes(x = target_picks, y = bf), alpha = 0.1) +
#   geom_smooth(aes(x = target_picks, y = bf), method = "loess") +
#   xlab(sprintf("# Target Picks out of %d Total Picks", Npicks)) +
#   # scale_y_log10("Bayes Factor of Null Plots") +
#   ggtitle("Change in Bayes Factor of Null Plots with Increasing Signal")

ggplot() +
  geom_hline(aes(yintercept = 1), color = "red") +
  geom_text(aes(x = 21, y = 1, label = "BF = 1"), vjust = 1, color = "red") +
  geom_boxplot(aes(x = target_picks, y = bf, group = cut_width(target_picks, 1)),
               data = filter(bf, type == "null"),
               outlier.shape = 1) +
  xlab(sprintf("# Target Picks out of %d Total Picks", Npicks)) +
  ylab("Bayes Factor of Null Plots") +
  ggtitle("Change in Bayes Factor of Null Plots with Increasing Signal")

rm(tmp, bf, bf.sim)
@

\begin{figure}
\begin{subfigure}[b]{.49\textwidth}
\caption{\label{fig:lp-114}Example lineup. }
\includegraphics[width=\textwidth]{lineup-images/e30ff06449a4b7664fe3109f7e2e996f.pdf}
\end{subfigure}
\begin{subfigure}[b]{.49\textwidth}
\caption{\label{fig:posterior2}Posterior densities for the choosing panel \#$i$. }
<<pics2, dependson='posterior', echo=FALSE,  fig.width=8, fig.height = 8, out.width='\\textwidth'>>=

# show one of the results:
i <- 2

lpsXXX <- data.frame(rdirichlet(5000, alpha+turk19.picks$counts[i][[1]]))
lpsXXXm <- gather(lpsXXX, key = "variable")
lpsXXXm$variable <- as.numeric(gsub("X", "", lpsXXXm$variable))

counts <- turk19.picks[i, "counts"][[1]][[1]]
#probs <- turk19.picks[i, "post_prob"][[1]][[1]]
#preprobs <- turk19.picks[i, "pre_prob"][[1]][[1]]
# bfactor <- turk19.picks[i, "bfactor"]$bfactor[[1]]$avg
bfactor <- turk19.picks[i, "bfactor"]$bfactor[[1]] %>% unlist()
dframe <- data.frame(variable = 1:20, Bfactor= round(bfactor,2))

ymax <- 1:20 %>% lapply(function(i) max(density(subset(lpsXXXm, variable == i)$value)$y)) %>% unlist %>% max

qplot(value, geom="density", data=lpsXXXm, fill=I("grey50"),
      colour=I("grey45"), alpha=I(0.5)) +
  facet_wrap(~variable) + xlim(c(0,1)) +
  theme_bw() +
  xlab("Posterior probability to pick plot") +
  ggtitle(sprintf("Pic ID %s (based on %.1f picks)", turk19.picks$pic_id[i],
                  sum(turk19.picks$counts[i][[1]]))) +
  geom_text(data=dframe, aes(label = Bfactor), x = 1, y = 0.9*ymax, size = 5,
            colour="grey70", hjust="inward", vjust="inward")
@
\end{subfigure}
\caption{\label{fig:xpl-114} Lineup (left) and posterior densities (right) corresponding to evaluations by independent observers.}
\end{figure}

\begin{figure}
\begin{subfigure}[b]{.49\textwidth}
\caption{\label{fig:lp-114}Example lineup. }
\includegraphics[width=\textwidth]{lineup-images/5f9885168e3a02f57ab7216e9f76141d.pdf}
\end{subfigure}
\begin{subfigure}[b]{.49\textwidth}
\caption{\label{fig:posterior2}Posterior densities for the choosing panel \#$i$. }
<<pics3, dependson='posterior', echo=FALSE,  fig.width=8, fig.height = 8, out.width='\\textwidth'>>=
dname <- gsub("-turk16","", subset(pics19, pic_id == 104)$data_name)
dname <- gsub("sd\\.","sd", dname)
dname <- gsub("trend", "line", dname)

samedata <- subset(pics16, data_name == dname)
# subset(samedata, test_param == "turk16-colorEllipse")
# identifies 5f9885168e3a02f57ab7216e9f76141d

# show one of the results:
i <- subset(samedata, test_param == "turk16-colorEllipse")$pic_id

lpsXXX <- data.frame(rdirichlet(5000, alpha+turk16.picks$counts[i][[1]]))
lpsXXXm <- gather(lpsXXX, key = "variable")
lpsXXXm$variable <- as.numeric(gsub("X", "", lpsXXXm$variable))

counts <- turk16.picks[i, "counts"][[1]][[1]]
#probs <- turk16.picks[i, "post_prob"][[1]][[1]]
#preprobs <- turk16.picks[i, "pre_prob"][[1]][[1]]
# bfactor <- turk16.picks[i, "bfactor"]$bfactor[[1]]$avg
bfactor <- turk16.picks[i, "bfactor"]$bfactor[[1]] %>% unlist()
dframe <- data.frame(variable = 1:20, Bfactor= round(bfactor,2))

ymax <- 1:20 %>% lapply(function(i) max(density(subset(lpsXXXm, variable == i)$value)$y)) %>% unlist %>% max

qplot(value, geom="density", data=lpsXXXm, fill=I("grey50"),
      colour=I("grey45"), alpha=I(0.5)) +
  facet_wrap(~variable) + xlim(c(0,1)) +
  theme_bw() +
  xlab("Posterior probability to pick plot") +
  ggtitle(sprintf("Pic ID %s (based on %.1f picks)", turk16.picks$pic_id[i],
                  sum(turk16.picks$counts[i][[1]]))) +
  geom_text(data=dframe, aes(label = Bfactor), x = 1, y = 0.9*ymax, size = 5,
            colour="grey70", hjust="inward", vjust="inward")

@
\end{subfigure}
\caption{\label{fig:xpl-124} Lineup (left) and posterior densities (right) corresponding to evaluations by independent observers.}
\end{figure}

\hh{can we combine multiple lineups?}
\svp{You mean compare which plots are most likely to be selected out of several sets of sub-plots? That's an interesting idea, but I'm not sure that there's an obvious way to do that... Unless you just ``integrate" over multiple lineups and selections? That can't be valid, can it?}

\hh{XXX Bayesian equivalent of a logistic regression with random effects, jags? }
\bibliographystyle{asa}
\bibliography{references}

\end{document}
