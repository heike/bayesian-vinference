\documentclass[12pt]{article}
\usepackage{amssymb}
\usepackage{natbib}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{mathrsfs}
\usepackage{bm}
\usepackage{multirow}
\usepackage{hyperref}
% \usepackage{endfloat} % Figures to the end of the document

\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png}
%---------------------------------------------------
%                 Editing Commands
\newcommand{\hh}[1]{{\color{magenta} #1}}
\newcommand{\svp}[1]{{\color{darkgray} #1}}
\newcommand{\fix}[1]{{\color{blue} #1}}
\newcommand{\todo}[1]{{\color{purple} #1}}

%---------------------------------------------------
%                 Placing Figures
\usepackage[font=small,skip=5pt]{caption}
\usepackage{subcaption}
\usepackage{afterpage}
\usepackage{rotating}
\usepackage[dvipsnames,svgnames,table]{xcolor}
\graphicspath{{figure/}}

%---------------------------------------------------
% Define new environment
\newtheorem{theorem}{Theorem}[section]
\newtheorem{algorithm}[theorem]{Algorithm}
%---------------------------------------------------

%\pdfminorversion=4
% NOTE: To produce blinded version, replace "0" with "1" below.
\newcommand{\blind}{0}

% DON'T change margins - should be 1 inch all around.
\addtolength{\oddsidemargin}{-.5in}%
\addtolength{\evensidemargin}{-.5in}%
\addtolength{\textwidth}{1in}%
\addtolength{\textheight}{1.3in}%
\addtolength{\topmargin}{-.8in}%


\begin{document}

% \bibliographystyle{natbib}

\def\spacingset#1{\renewcommand{\baselinestretch}{#1}\small\normalsize}
\spacingset{1}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\if0\blind {
  \title{\bf A Bayesian approach to visual inference}
  \author{Susan VanderPlas, Heike Hofmann\thanks{
    The authors gratefully acknowledge funding from the National Science Foundation Grant \# DMS 1007697. All data collection has been conducted with approval from the Institutional Review Board IRB 10-347}\hspace{.2cm}\\
    Department of Statistics and Statistical Laboratory, Iowa State University}%
  \maketitle%
} \fi

\if1\blind {
  \bigskip
  \bigskip
  \bigskip
  \begin{center}
    {\LARGE\bf A Bayesian approach to visual inference}
\end{center}
  \medskip
} \fi

\section{Introduction}

% Introduction to graphical testing: Rorschach vs. Visual Inference

% Graphical Testing vs. Statistical Testing - power improvements w/ additional people

% Something about the power of the human visual system? Don't want to get too off topic...
<<setup, echo = F, include = F>>=
library(tidyverse)
knitr::opts_chunk$set(echo = F, message = F)
# theme_set(theme_bw())
@

\section{A Bayesian's Statistical Lineup}
While visual inference was initially developed to mimic frequentist hypothesis tests with the standard threshold of $p = 0.05$, the method itself does not require adherence to frequentist methods. In this section, we show one possible Bayesian framework for visual inference, using a Dirichlet-multinomial distribution to represent the probabilities of selecting each subplot and the observed participant selections.

\subsection{Lineup Model Specification}
We will begin with a generic $m$-panel lineup, with selection probabilities $\theta_i, i = 1, ..., m$ where $\sum_{i=1}^m \theta_i = 1$, that is, the participant will select one (and only one) panel from the lineup as the most different. Our lineup has been evaluated by $K$ individuals, with $c_i, i = 1, ..., m$ the selection count for each panel, and $K = \sum_{i=1}^m c_i$.

A natural data model for this data is the Multinomial distribution, which has parameters $N, \bm{\theta}$, where $N$ describes the total number of events (that is, $N=K$) and $\bm{\theta} = \theta_1, ..., \theta_m$ describes the probabilities of each event occurring. We will fix $K$, as that is controlled by the experimental design, and model $\bm{\theta}$.

\begin{align}\label{eqn:multinomial-pmf}
f(\bm{c}|K, \bm{\theta}) & = \frac{K!}{c_1! \cdots c_m!} \prod_{i=1}^m \theta_i^{c_i}
\end{align}

We assign prior probability to $p$ using a Dirichlet distribution with concentration hyperparameter $\bm{\alpha}$, which happens to be conjugate to the multinomial distribution. As the position of the panels within the lineup are random, we use a symmetric Dirichlet distribution, with $\alpha_i = \alpha, i = 1, ..., m$, that is, the concentration hyperparameter is constant. This allows us to vary the lineup difficulty through the hyperparameter $\alpha$ without having to specify which plot $i$ is the target plot.

The pdf of the symmetric Dirichlet distribution is
\begin{align}\label{eqn:dirichlet-pdf}
f(\bm{\theta}|\alpha) & = \frac{\left(\Gamma(\alpha)\right)^m}{\Gamma(m\alpha)} \prod_{i=1}^m \theta_i^{\alpha - 1}
\end{align}

Using the conjugate relationship between the Dirichlet and Multinomial distributions, we then get the posterior distribution as the Dirichlet$(\bm{c + \alpha})$ distribution.

\begin{align}\begin{split}\label{eqn:full-model-specification}
(\alpha_1, ..., \alpha_m) = \bm{\alpha} &= \text{concentration hyperparameter}\\
(c_1, ..., c_m) = \bm{c} &= \text{observed plot selections}, \sum_{i=1}^m c_i = K\\
p(\bm{\theta}) &\sim Dirichlet(\bm\alpha) \\
f(\bm{c} | \bm{\theta}) & \sim Multinomial(\bm\theta, K)\\
p(\bm\theta | \bm{c}, \bm{\alpha}) & \sim Dirichlet(\bm{c} + \bm{\alpha})
\end{split}\end{align}

where $Multinomial(\bm\theta, K)$ is defined as in \autoref{eqn:multinomial-pmf} and $Dirichlet(\bm\alpha)$ is defined as in \autoref{eqn:dirichlet-pdf}.

Typically, when evaluating lineups, we compare the number of target plot identifications with the aggregate number of null plot identifications (see \citet{majumder2013validation}). This is equivalent to the marginal distribution of $c_t$, where $t \in 1, ..., m$ is the index of the target panel in the lineup. The equivalent Bayesian version takes the form of a Beta-Binomial model.

\begin{align}\begin{split}\label{eqn:marginal-model-specification}
\alpha &= \text{concentration hyperparameter}\\
c_t &= \text{target plot selections},\\
K &= \text{total evaluations}\\
p(\theta_t) &\sim Beta(\alpha, (m-1)\alpha) \\
f(c_t | \theta_t) & \sim Binomial(\theta_t, K)\\
p(\theta_t | \bm{c_t}, \alpha) & \sim Beta(c_t + \alpha, K - c_t + (m-1)\alpha)
\end{split}\end{align}

From this formulation, we can construct a Bayesian analogue of the frequentist p-value proposed in \citet{majumder2013validation} using Bayes factors.
\subsection{Bayes Factors for Lineups}

The frequentist model used in \citet{majumder2013validation} assumes $\theta_t = 1/m$, that is, $\theta_t$ is fixed and equal to the selection probability of every other panel in the lineup. This assumption is unreasonable, so in more recent analyses of lineups, visual p-values for lineups have been calculated using the mass function
\begin{align}
P(C\geq x) = \sum_{x = C}^{K} \binom{K}{x} \frac{1}{B(\alpha, (m-1)\alpha)}\cdot B(x+\alpha, K-x+(m-1)\alpha)\label{eqn:sim-pmf}
\end{align}
where $C$ is the number of data panel detections and $K$ is the number of independent evaluations of the lineup. This value has been computed in the past by simulation, assuming $\alpha=1$, but the more general solution is useful to consider in this context. The visual p-value is then compared to a threshold of 0.05, and if it is smaller, we reject the hypothesis that every plot is equally likely to be selected.

We will first consider the general case of constructing a Bayes Factor for an entire lineup (e.g. all 20 panels), and then we will consider the marginal Bayes factor which is more comparable to the approaches in \citet{majumder2013validation} and \autoref{eqn:sim-pmf}.

\subsubsection{Marginal Bayes Factors for Target Plots}

\subsubsection{Full Lineup Bayes Factors}

\subsubsection{Caveats}

We know that it is unreasonable to assume that the selection probability of every null plot is equal: null plots are randomly generated, and occasionally, the randomly generated plot will have an interesting feature (that may or may not be present in the target plot). When that occurs, the interesting null plot will be selected more frequently than the other nulls, despite being generated by the same distribution. The ability to identify stimuli as being different from one another is a fundamental part of cognition; the abstractions that allow us to use the terms `same' and `different' are fundamental to human intelligence\citep{mingWhenThingsAre2017}. As a result, when presented with a lineup, we will typically gravitate towards one or two panels which are different from our mental representation of a generalized panel on some measure, though not always the measure that's under investigation. The number of panels which appear to be different from a generalized lineup panel formed after viewing the lineup is a function of $\alpha$, the hyperparameter in \autoref{eqn:dirichlet-pdf} and \autoref{eqn:full-model-specification}. As a result, it's important to understand the effect of $\alpha$ on the posterior distribution.

\subsection{Dirichlet Hyperparameter}

In conjunction with the Multinomial data model and a symmetric Dirichlet prior, $\alpha$ provides the equivalent of pseudo-observations for each plot; that is, the effect of $\alpha$ is equivalent to adding $\alpha$ observations to each panel in the lineup. When $\alpha$ is small, these pseudo-observations have relatively little influence, but when $\alpha$ is large, the pseudo-observations can quickly dwarf any information provided by the data. This is particularly true for the marginal Beta-Binomial model, where the equivalent of $(m-1)\alpha$ pseudo-observations are added. In most lineup studies, a plot might be evaluated between 10 and 30 times; with a $m=20$ lineup, even $\alpha = 1$ can easily dominate the participant selection data.

In addition to the pseudo-observation interpretation, $\alpha$ provides information about the number of panels in a lineup which are likely to attract participant interest.
% Stolen from heike/lineup-scenarios
When $\alpha = 1$ the symmetric Dirichlet distribution is uniform on the $m-1$ dimensional simplex. When $\alpha < 1$ the mass of the distribution is along the edges of the simplex, where most values of $\theta_i$ will be close to 0. When $\alpha>1$, the mass of the distribution is in the center of the simplex, with most of the $\theta_i$ having similar values. \autoref{fig:simplex} shows ternary plots of values simulated from a 3-dimensional Dirichlet distribution which illustrate this effect.

<<simplex, echo=FALSE, out.width='\\textwidth', fig.width=12, fig.height=4, fig.cap = "Dirichlet distributed samples on the 2-dimensional simplex.">>=
simplex <- purrr::map_df(.x = c(1/3, 1, 3), ~data.frame(
  gtools::rdirichlet(5000, alpha = rep(.x, 3))
), .id = "alpha") %>%
  rename(p1 = X1, p2 = X2, p3 = X3) %>%
  mutate(alphalabel = factor(alpha, levels = 1:3, labels = c("alpha: 1/3", "alpha: 1", "alpha: 3")))

ggtern::ggtern(aes(x = p1, y = p2, z = p3), data = simplex) +
  geom_point(alpha = .075, shape = 16) +
  facet_wrap(~alphalabel, labeller = "label_parsed") +
  theme(panel.background = element_rect(colour = "black"))
@
% End stolen from heike/lineup-scenarios

<<set-theme-bw, include = F>>=
theme_set(theme_bw())
@

While graphical illustrations of the 20-dimensional dirichlet distribution are more difficult, we can use prior predictive simulations to assess the meaning of $\alpha$ as it relates to how many panels in a lineup attract participant attention. \autoref{fig:prior-predictive} shows simulated $c_i$ counts (sorted for visual clarity) for several values of $\alpha$; it is evident that for $\alpha<0.05$ only one panel of the lineup receives significant attention, while for $\alpha> .25$, participant attention is divided among several interesting panels of the lineup.

<<prior-predictive, echo = F, fig.cap = "Prior predictive distribution of number of participant selections of panels (sorted by frequency) for different values of $\\alpha$, with $K=20$ plot evaluations. Low values of $\\alpha$ have fewer plots with any participant selections, while higher values of $\\alpha$ have more plots with participant selections.", fig.width = 8, fig.height = 4, out.width = "\\textwidth" >>=
sim_lineup_model <- function(alpha, m = 20, k = 20, N = 50) {
  theta <- gtools::rdirichlet(1, rep(alpha, m))
  sels <- rmultinom(N, size = k, prob = theta)
  sels
}

alphas <- c(.001, .02, .05, .1, .5, 1, 2, 5, 20, 1000)
prior_pred <- tibble(alpha = alphas,
                     plot_sels = purrr::map(alpha, sim_lineup_model, N = 100)) %>%
  mutate(
    sel_ordered = purrr::map(plot_sels, ~apply(., 2, sort, decreasing = T)),
    sel_ordered_long = purrr::map(
      sel_ordered,
      ~tibble(idx = rep(1:nrow(.x), times = ncol(.x)),
              rep = rep(1:ncol(.x), each = nrow(.x)),
              sels = as.vector(.x, mode = "numeric")))
  ) %>%
  select(-plot_sels, -sel_ordered) %>%
  unnest() %>%
  arrange(alpha) %>%
  mutate(label = sprintf("alpha == %f", alpha) %>% factor(levels = sprintf("alpha == %f", alphas), ordered = T))

ggplot(prior_pred) +
  geom_path(aes(x = idx, y = jitter(sels, amount = .3), group = interaction(rep, alpha)), alpha = .05) +
  facet_wrap(~label, labeller = label_parsed, nrow = 2) +
  scale_x_continuous("Ordered panel number") +
  scale_y_continuous("# Simulated Panel Selections (of 20 evaluations)")

@

A modification of the frequentist paradigm developed in \citet{majumder2013validation} and released as a technical report \todo{get citation!} simulates p-values from a Dirichlet distribution with $\alpha=1$; based on the prior predictive distributions alone, $\alpha=1$ does not appear to fit the observed data or theoretical process (e.g. the tendency to identify even small differences from among similar things) well.

Clearly, the choice of $\alpha$ is critical under both the frequentist and Bayesian model paradigms. From a practical perspective, the number of plots which are visually salient and thus likely to be selected by participants is a factor of the lineup design (zero, one, or two targets), null plot generation method, and possibly the form of the plot (aesthetics, geometric representations, scales). In the next section, we discuss a method for estimating $\alpha$ from Rorshach or standard lineups.

\section[Estimating alpha]{Estimating $\alpha$}
\subsection{Derivation of MLE for $\alpha$}
% modified from heike/lineup-scenarios
In order to estimate $\alpha$ from the null plots of a lineup, let $m_0$ be the number of null plots in an $m$- panel lineup. If the lineup is a Rorshach lineup, then $m=m_0$. We can estimate $\alpha$ using a set of such lineups, $j=1, ..., n$. The likelihood function is then
\begin{align}
\mathscr{L}(\alpha|\theta) &= \prod_{j=1}^n \left(\frac{1}{B(\alpha)}\right)^{m_0} \prod_{i=1}^{m_0} \theta_{ij}^{\alpha - 1}\nonumber\\
& = \left(\frac{\Gamma(\alpha m_0)}{\left(\Gamma(\alpha)\right)^{m_0}}\right)^n \prod_{ij} \theta^{\alpha-1}_{ij}
\end{align}
and the derivative of the log-likelihood function can be calculated as
\begin{align}
\ln \mathscr{L}(\alpha|\theta) & = n \ln \Gamma(\alpha m_0) - nm_0\ln\Gamma(\alpha) + \sum_{ij}(\alpha-1)\ln \theta_{ij}\nonumber\\
\frac{d}{d\alpha}\ln \mathscr{L}(\alpha|\theta) &= nm_0\psi(\alpha m_0) - nm_0\psi(\alpha) + \sum_{ij} \ln \theta_{ij}
\end{align}
where $\psi(x)$ is the digamma function, $\psi(x) = \frac{d}{dx}\ln\Gamma(x)$.
Setting this to zero, we find that the MLE of $\alpha$ can be obtained empirically from the sum of the log probabilities $\theta_{ij}$.
\begin{align}
0 &= nm_0\psi(\alpha m_0) - nm_0\psi(\alpha) + \sum_{ij} \ln \theta_{ij} \nonumber\\
nm_0\psi(\alpha) - nm_0\psi(\alpha m_0) &= \sum_{ij} \ln \theta_{ij}\nonumber\\
\psi(\alpha) - \psi(\alpha m_0) & = \frac{1}{nm_0}\sum_{ij} \ln \theta_{ij} \label{eqn:mle}
\end{align}
% end modified from heike/lineup scenarios

The second derivative of the log likelihood function uses the trigamma function, $\psi_1(x) = \frac{d^2}{dx^2} \ln \Gamma(x)$. $\psi_1(x)$ can also be written as the series $\psi_1(x) = \sum_{z=0}^\infty \frac{1}{(z + n)^2}$. Thus,
\begin{align}
\frac{d^2}{d\alpha^2}\ln \mathscr{L}(\alpha|\theta) &= nm_0^2\psi_1(\alpha m_0) - nm_0\psi_1(\alpha)\\
& = nm_0^2\left(\sum_{x=0}^\infty \frac{1}{(\alpha m_0 + x)^2} - \sum_{x=0}^\infty \frac{1}{m_0(\alpha + x)^2}\right)\nonumber\\
& = nm_0^2\sum_{x=0}^\infty \left(\frac{1}{(\alpha m_0 + x)^2} - \frac{1}{m_0(\alpha + x)^2}\right) \nonumber\\
& = nm_0^2\sum_{x=0}^\infty \frac{m_0(\alpha + x)^2 - (m_0\alpha + x)^2}{m_0(\alpha m_0 + 1)^2(\alpha + x)^2}\leq 0 \text{ for } m_0 \geq 1, \alpha > 0 \nonumber\\
& \hphantom{=} \text{ as } m_0(\alpha+x)^2 \leq (\alpha m_0 + x)^2 \text{ for } m_0 \geq 1, \alpha > 0\nonumber
\end{align}
The empirical solution to \autoref{eqn:mle} is thus a local maximum.

% stolen from heike/lineup-scenarios
<<alpha-ml, include = F>>=
source("code/alpha_ml.R")
@

% end stolen from heike/lineups scenarios
Thus, the MLE of $\alpha$ is the $\alpha$ satisfying the equation \autoref{eqn:mle}.

\subsection{Pooling null evaluations}
The MLE for $\alpha$ in \autoref{eqn:mle} allows for the combination of evaluations of multiple sets of null plots (either from Rorshach lineups or lineups with one or more target panels), but in order for this combination of data to be meaningful, the following conditions should hold:
\begin{enumerate}
\item Null plots should be generated by the same model
\item Only plots with the same aesthetics should be pooled for $\alpha$ estimation
\item Selection method should be the same (e.g. single or multiple target plots)
\end{enumerate}

When estimating $\hat\alpha$ from null plot selections in a standard lineup (e.g. a lineup containing at least one target plot), there is the possibility that no null plots are selected. If this is a frequent occurrence, it may be necessary to pool across aesthetics or null model parameter sets in order to obtain reasonable $\hat\alpha$s. A more reliable and systematic way to estimate $\hat\alpha$ would be to include a Rorshach lineup for each set of parameters used to generate null plots. These Rorshach lineups could be integrated into the testing procedure, or could be part of a pilot study used to assess the null plot generating model before it is used in lineups with data targets.

% \todo{default of ?? if no null plots are selected.} \svp{I know we talked about the default, I just don't remember what it was... as sum(log theta) -> - infinity, alpha -> 0 from what I can tell empirically. }

Intuitively, $\alpha$ is related to the proportion of null plots which would have some visually interesting feature: if $\alpha$ is low, that is, $\alpha << 1$, $\theta$s generated by the model would tend to be close to zero, with one or two larger panel selection probabilities (that is, one or two of the panels would be significantly more noticable). If $\alpha$ is high, $\alpha >> 1$, $\theta$s generated by the model would be closer to $1/m_{0}$, that is, each panel would be approximately equally likely to be selected. We know that the data generating model is likely to affect $\alpha$, and from \citet{vanderplas:2017} we know that the aesthetics can also significantly effect the selection of panels in a lineup.

In order to illustrate the variability in $\hat\alpha$ estimates across different lineup studies and to get a sense of the range of reasonable $\hat\alpha$ values, we estimated $\alpha$ for several previous single-target lineup studies of various sizes and designs. In several of these studies, multiple panel selections were allowed; these are allocated as partial selections to each set of counts.


<<null-alpha-single-target, fig.cap = "Alpha estimates for several single-target lineup studies.", warning = F, message = F>>=
source("code/process_all_lineup_data.R")
plot_df %>%
  ggplot(aes(x = dataset2, y = alpha, color = type, group = presentation)) +
  facet_wrap(~study, scales = "free_x") +
  scale_color_manual("Selection\nType", values = c("orange4", "purple")) +
  geom_point(position = position_dodge(width = .3), shape = 1) +
  theme_bw() +
  theme(legend.position = c(1, 0), legend.justification = c(1, 0)) +
  scale_x_continuous("Dataset") +
  scale_y_continuous(expression(hat(alpha))) +
  ggtitle(expression(paste(hat(alpha), " for Single-target Lineup Studies")))
@

\autoref{fig:null-alpha-single-target} shows the estimated $\alpha$s for each set of data, parameters, and aesthetics used in the studies. In most studies, $\hat\alpha \approx 0.07$ (5\% - 95\% quantiles: \Sexpr{sprintf("%0.3f and %0.3f", quantile(filter(plot_df, !study %in% c("Study 5", "Study 6"))$alpha, .05), quantile(filter(plot_df, !study %in% c("Study 5", "Study 6"))$alpha, .95))}), with very few estimated values over 0.10. There are some exceptions: Study 5 and Study 6 have $\hat\alpha$ values between \Sexpr{sprintf("%0.3f and %0.3f", min(filter(plot_df, study == "Study 5")$alpha), max(filter(plot_df, study == "Study 5")$alpha))}, which is a much wider range. In these studies, it also appears that plots with multiple selections allowed tend to have higher $\hat\alpha$ values, suggesting that multiple plot selections might allow for more diffusion of probabilities over multiple null plots. This effect might be heightened by increased lineup difficulty, which would also tend to increase $\hat\alpha$ values. One lineup from Study 5 is shown in \autoref{fig:hard-lineup}; only one participant identified the data target from among the nulls, suggesting that this is a difficult lineup, but the diffusion of identifications across many null panels indicates that the null data model generates plots with a relatively homogeneous level of visual interest.

\begin{figure}
\centering
\includegraphics[width=.6\textwidth]{lineup-images/turk11-filec2a72fe67dcf-multiple.pdf}
\caption{A lineup from Study 5. The target plot is in panel 7+7. Only one participant identified the target plot in 24 lineup evaluations. A total of 15 panels in this lineup were selected, indicating that the $\hat\alpha$ associated with this plot should be relatively large.}\label{fig:hard-lineup}
\end{figure}

One issue with lineup experiments is that participants sometimes identify features in the null plots which are interesting, but not necessarily interesting in the same way as the feature under investigation that is shown in the data plot. In some cases, this is because the lineup is particularly challenging or the target plot's effect is not visually significant, but in others, it can be an indicator that the null plot generation model is not adequately reproducing features in the data. In large lineup experiments, it can be difficult to screen every panel of every lineup for these issues, resulting in systematic problems such as those in \citet{vanderplas:2017}. In that study, null panel data were clustered using k-means; this clustering occasionally produced clusters of 1-3 points or clusters which were oddly shaped, and the panels showing these data sets were frequently identified by participants even though the original intent of the experiment was to assess the visual salience of clustering and linear trends in the presence of different aesthetic combinations. In the case of clusters of one or two points, estimation of a 95\% bounding ellipse failed, providing an unintended feature which participants noticed, resulting in significant null plot identifications. \autoref{fig:featurehierarchy-null-model-sucks} shows two lineups which contain the same data; the clustering issues are much more noticable in the lineup with color, shape, and bounding ellipse aesthetics.

<<null-alpha-est>>=
source("code/turk16_null_alpha.R")
@

<<featurehierarchy-null-model-sucks, fig.width = 12, fig.height = 6, fig.cap = "A two-target lineup from \\citet{vanderplas:2017}, plotted with different aesthetic combinations. The two targets are in plot 11+8 (clustering) and 2+2 (linear trend). In plots 10, 11, 15, and  17, the estimation of a bounding ellipse in a null plot failed due to insufficient points in the cluster. This deficiency is less apparent in the second lineup, which only has a regression line, as the aesthetics which emphasize grouping are not shown.", warning = F, message=F>>=
source("code/turk16_plots.R")
turk16_lineup_dat <- read_csv("data/Turk16/Image_Data/set-46-k-5-sdline-0.45-sdgroup-0.25.csv")

turk16_lineup_alphas <- filter(t16_null_alpha_plotwise, set_number == 46, aes_type %in% c("trend", "colorShapeEllipse")) %>% arrange(aes_type)

gridExtra::grid.arrange(
  suppressWarnings(gen.plot(turk16_lineup_dat, c("Color", "Shape"), c("Ellipses"))) +
    coord_fixed() + scale_x_continuous(limits = c(-3, 2.75)) + scale_y_continuous(limits = c(-3, 2.75)),

  suppressWarnings(gen.plot(turk16_lineup_dat, NULL, "Reg. Line")) +
    coord_fixed() + scale_x_continuous(limits = c(-3, 2.75)) + scale_y_continuous(limits = c(-3, 2.75)),
  nrow = 1
)
@

One possible solution to this problem is to run a small pilot study in which a Rorshach lineup is used to examine the selection frequency of different null plots. If one or two null plots are systematically selected from this Rorshach lineup, or if the $\hat\alpha$ values are highly variable, then the data-generating model may need to be examined for unintended effects such as those in \citet{vanderplas:2017}. Alternately, $\hat\alpha$ can be estimated from the null plot selections of a standard lineup, though if the lineup is relatively easy and null plots are selected infrequently, these estimates may be unstable.

It is reasonable to think that $\hat\alpha$ would be different for the two lineups in \autoref{fig:featurehierarchy-null-model-sucks} even though the underlying data is the same: the color, shape, and ellipse aesthetics emphasize the missing elements and small cluster size, while this deficiency is much less apparent in the second lineup, which contains no aesthetic cues to indicate data clustering. We can estimate plot-specific $\hat\alpha$ for each of the plots shown in \autoref{fig:featurehierarchy-null-model-sucks}; the values are \Sexpr{sprintf("%0.3f and %0.3f", turk16_lineup_alphas$alpha[1], turk16_lineup_alphas$alpha[2])}, respectively. Thus, in the null plots shown in the first figure, which has color, shape, and ellipse aesthetics, $\theta_i, i = 1, ..., m_0$, there is more diffusion of probability over several plots than in the second lineup, which has only a regression line added to the plot.

We can examine the $\hat\alpha$ estimates for each set of aesthetics to explore empirical support for this hypothesis. The full experiment details can be found in \citet{vanderplas:2017}; for the purposes of this reanalysis dealing only with the null plots, data was generated using three parameters: $k \in c(3, 5)$, the number of clusters, $\sigma_T$, the standard deviation around the trend line, and $\sigma_C$, the deviation around the cluster centers. Three values of $\sigma_T$ and $\sigma_C$ were used to represent varying degrees of difficulty, with small $\sigma$ values hypothesized to be easier than large $\sigma$ values. Thus, there are a total of 18 parameter combinations, and at each parameter combination there are 3 replicate lineup data sets, for a total of 54 datasets. Each dataset is rendered in 10 different aesthetic combinations, for a total of 540 plots.

With this design in mind, individual $\hat\alpha$ values were calculated from the null plot selection data for each lineup, to get a sense of the variability in the $\hat\alpha$ estimates. In some lineups, null plots were never selected; estimates have been excluded for these plots. \autoref{fig:all-null-alphas} shows the results by aesthetic for each lineup data set used in \citet{vanderplas:2017}.
<<all-null-alphas, fig.cap = "Alpha estimates for each lineup image with at least 5 null panel selections, with aggregate estimates for each parameter set and aesthetic combination with a total of 5 null panel selections across multiple plots. There are some differences between aesthetics in average $\\hat\\alpha$, but overall, most $\\alpha$ values are estimated to be around 0.7. The variability in $\\hat\\alpha$ increases with the value of $\\sigma_C$ and $\\sigma_T$, the trend and cluster variability parameters. Note that on the y-axis, aesthetics are indicated as follows: C = color, L = ellipse, S = shape, T = trend line, E = error band. $\\hat\\alpha$s tend to be more variable when color aesthetics are present - if only one null plot has an unequal group, $\\alpha$ will tend to be very small; if more than one null plots have unequal groups, $\\alpha$ tends to be larger. Pooled estimates of the 3 plots generated with the same parameters and displayed with the same aesthetics are shown with an 'x'.", fig.width = 8, fig.height = 6>>=

plot_t16_alpha_df <- t16_null_alpha_plotwise %>%
  mutate(valtype = "Individual Plot") %>%
  bind_rows(
    mutate(t16_null_alpha_setwise, valtype = "Pooled")
  ) %>%
  mutate(label = sprintf("Plots %02.0f-%02.0f", set_min, set_min+2),
         klab = sprintf("k == %d", k),
         siglab1 = paste("sigma[T] == ", round(sdline, 2)),
         siglab2 = paste("sigma[C] == ", round(sdgroup, 2)),
         aes_type = fix_plot_names(aes_type)) %>%
  ungroup() %>%
  mutate(sig_int = interaction(sdline, sdgroup) %>% factor() %>% as.numeric()) %>%
  group_by(k) %>%
  mutate(y_val = (sig_int - 6)/9) %>%
  ungroup()

plot_t16_alpha_segs <- plot_t16_alpha_df %>%
  group_by(aes_type, siglab1, siglab2, sig_int) %>%
  summarize(minp = min(alpha), maxp = max(alpha), y_val = unique(y_val))

ggplot() + coord_flip() +
  scale_size_continuous("# Null Evaluations", range = c(1, 4)) +
  geom_segment(aes(x = y_val, xend = y_val, y = minp, yend = maxp),
               data = plot_t16_alpha_segs,
               alpha = .25) +
  geom_point(aes(y = alpha, x = y_val, size = n_total,
                 color = factor(k),
                 shape = valtype),
             data = plot_t16_alpha_df) +
  scale_shape_manual("Estimate Type", values = c("Individual Plot" = 1, "Pooled" = 4)) +
  scale_color_manual("# Clusters", values = c("3" = "purple", "5" = "orange")) +
  ylab("") +
  scale_y_continuous(name = expression(alpha)) +
  scale_x_continuous(breaks = NULL) +
  # facet_grid(siglab1 ~., labeller = label_parsed) +
  facet_grid(aes_type ~ .) +
  theme_bw() +
  theme(legend.position = "bottom", axis.title.y = element_blank())
@

<<all-null-alpha-pooled, fig.cap = "Alpha estimates calculated by pooling within null plot generating parameters and between null plot generating parameters. It is clear that the introduction of color and other aesthetics which highlight clustering causes an increase in $\\hat\\alpha$ estimates when data is aggregated; this effect is likely due to the inclusion of plots with several null targets with groups of noticably different sizes; there is significant variability in the $\\hat\\alpha$ estimates based on single data sets and based on single parameter sets because the randomly generated null plot data does not consistently produce the same number of null plots with this interesting characteristic.", fig.width = 4, fig.height = 5>>=
t16_null_alpha_setwise %>%
  mutate(valtype = "Pooled (single parameter set)") %>%
  bind_rows(
    mutate(t16_null_alpha_aeswise, valtype = "Pooled (all parameter sets)")
  ) %>%
  mutate(label = sprintf("Plots %02.0f-%02.0f", set_min, set_min+2),
         klab = sprintf("k == %d", k),
         siglab1 = paste("sigma[T] == ", round(sdline, 2)),
         siglab2 = paste("sigma[C] == ", round(sdgroup, 2)),
         aes_type = fix_plot_names(aes_type)) %>%
ggplot(aes(x = alpha, y = aes_type)) +
  geom_point(aes(shape = valtype, alpha = valtype)) +
  scale_shape_manual("Estimate Type", values = c("Pooled (single parameter set)" = 4, "Pooled (all parameter sets)" = 20)) +
  scale_alpha_manual("Estimate Type", values = c("Pooled (single parameter set)" = .5, "Pooled (all parameter sets)" = 1)) +
  ylab("") +
  scale_x_continuous(name = expression(alpha)) +
  theme_bw() +
  theme(legend.position = "bottom", axis.title.y = element_blank())
@

The estimated $\hat\alpha$ value can then be used either in the specification of the null model $\alpha$ ($\alpha_{M_2}$) or in the calculation of the visual p-value under the frequentist framework. Currently, in either scenario, the data used in the calculation are the target plot identifications and the sum of all null plot identifications; the individual values of the null plot identifications are not used. These data can be reclaimed to estimate a general $\alpha$ for the overall null model generation scheme, or, in an ideal situation, Rorshach lineups could be used to estimate $\alpha$ directly without any possible contamination effects induced by the presence of target plots.

\section{Impact of $\hat\alpha$ Selection}



\bibliographystyle{asa}
\bibliography{references}




\end{document}
