\documentclass[12pt]{article}
\usepackage{amssymb}
\usepackage{natbib}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{mathrsfs}
\usepackage{bm}
\usepackage{multirow}
\usepackage{hyperref}
% \usepackage{endfloat} % Figures to the end of the document

\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png}
%---------------------------------------------------
%                 Editing Commands
\newcommand{\hh}[1]{{\color{magenta} #1}}
\newcommand{\svp}[1]{{\color{darkgray} #1}}
\newcommand{\fix}[1]{{\color{blue} #1}}
\newcommand{\todo}[1]{{\color{purple} #1}}

%---------------------------------------------------
%                 Placing Figures
\usepackage[font=small,skip=5pt]{caption}
\usepackage{subcaption}
\usepackage{afterpage}
\usepackage{rotating}
\usepackage[dvipsnames,svgnames,table]{xcolor}
\graphicspath{{figure/}}

%---------------------------------------------------
% Define new environment
\newtheorem{theorem}{Theorem}[section]
\newtheorem{algorithm}[theorem]{Algorithm}
%---------------------------------------------------

%\pdfminorversion=4
% NOTE: To produce blinded version, replace "0" with "1" below.
\newcommand{\blind}{0}

% DON'T change margins - should be 1 inch all around.
\addtolength{\oddsidemargin}{-.5in}%
\addtolength{\evensidemargin}{-.5in}%
\addtolength{\textwidth}{1in}%
\addtolength{\textheight}{1.3in}%
\addtolength{\topmargin}{-.8in}%


\begin{document}

In the past, we have compared this visual p-value to a threshold of 0.05, and if it is smaller, we rejected the hypothesis that every plot is equally likely to be selected. It is not necessary to rely on hypothesis testing for this analysis; an equally valid approach would be to compare two competing models: one with $\alpha \ll 1$, which allows for a smaller set of panels to be selected, and one with $\alpha \gg 1$, which would correspond to a more equal theoretical distribution of panel selections, using a Bayes Factor to quantify the evidence in favor of either model. This approach is derived in the next section.
% Now that we have some intuition for the effect of the value of $\alpha$, we can proceed with deriving a Bayes Factor for visual inference analysis.

\section{Bayes Factors for Lineups}\label{sec:bayesfactors}
Bayes factors are somewhat analogous to frequentist hypothesis tests~\citep{kassBayesFactors1995}, but to construct a Bayes factor for a lineup, we need two models to compare.
In order to construct a Bayes Factor which would be roughly equivalent to the standard lineup evaluation, we would compare two models with different hyperparameters: the model structure is the same, but in the first model, we would expect one or two of the panels to be selected more frequently (corresponding to a low value of $\alpha$); in the second, we would expect all panels to be selected approximately equally (corresponding to a high value of $\alpha$).

\begin{description}
\item[M1] $\alpha < 1$ - a small value of $\alpha$, indicating that one or two of the plots might tend to be selected more frequently.
\item [M2] $\alpha \geq 1$ - a large value of $\alpha$, suggesting that each plot is (approximately) equally likely to be selected.
\end{description}

\autoref{fig:prior-predictive} shows the sorted panel selection counts for several values of $\alpha$; note that even at $\alpha=1000$, all plots are not selected equally (the equivalent of the null hypothesis in the visual p-value calculation in \citet{majumder:2013}).

As with the direct p-value calculation, we will first consider the construction of a Bayes Factor for an entire lineup (e.g. all 20 panels), and then we will consider the marginal Bayes factor which is more comparable to the approach used to assess lineups in previous studies~\citep{majumder2013validation} (see  \autoref{eqn:sim-pmf}).

\subsection{Full Lineup Bayes Factors}

A full lineup Bayes factor would test the selection probabilities of the entire set of $m$ panels as a single unit, with no differentiation based on whether the panel shows null or target data. The multidimensional Bayes Factor for a lineup tests whether one or more panels are more likely to be selected (compared to a model where all panels are equally likely to be selected); it does not indicate which panel(s) are more likely. As such, it is of somewhat limited utility in the analyses of lineups which have been conducted to date, but is provided here to support the later calculation of a marginal Bayes factor which is analogous to the visual p-value calculation.

Let $\alpha_{M_1} < 1$ be the prior concentration hyperparameter for model 1, and $\alpha_{M_2} \geq 1$ be the prior concentration hyperparamer for model 2. If we assume that both models are equally likely a priori, then the prior model odds cancel, and we can derive the bayes factor comparing model 1 to model 2 for an entire lineup as:

  % Derive bayes factors for entire lineups
\begin{align}
BF(M_1, M_2) = &  \frac{\displaystyle\int_\theta p(\theta | \alpha_{M_1}) f(\bm{c} | \bm\theta, \alpha_{M_1}) d\bm\theta}
{\displaystyle\int_\theta p(\theta | \alpha_{M_2}) f(\bm{c} | \bm\theta, \alpha_{M_2}) d\bm\theta} \nonumber\\
=  &  \frac
{\int\left(\frac{1}{B(\bm\alpha_1)} \prod_{i=1}^m \theta_i^{\alpha_1 - 1}\right)\left(\frac{\left(\sum_{i=1}^m c_i\right)!}{c_1!\times \cdots\times c_m!} \prod_{i=1}^m \theta_i^{x_i}\right) d\bm\theta}
{\int\left(\frac{1}{B(\bm\alpha_2)} \prod_{i=1}^m \theta_i^{\alpha_2 - 1}\right)\left(\frac{\left(\sum_{i=1}^m c_i\right)!}{c_1!\times \cdots\times c_m!} \prod_{i=1}^m \theta_i^{x_i}\right) d\bm\theta}\nonumber\\
=  & \frac{B(\bm\alpha_2)}{B(\bm\alpha_1)}
\frac{\frac{\left(\sum_{i=1}^m c_i\right)!}{c_1!\times \cdots\times c_m!}}{\frac{\left(\sum_{i=1}^m c_i\right)!}{c_1!\times \cdots\times c_m!}}
\frac{\int \prod_{i=1}^m \theta_i^{\alpha_1 - 1 + c_i}d\bm\theta}{\int \prod_{i=1}^m \theta_i^{\alpha_2 - 1 + c_i}d\bm\theta}\nonumber\\
= & \frac{B(\bm\alpha_2)B(\bm\alpha_1+\bm{c})}{B(\bm\alpha_1)B(\bm\alpha_2+\bm{c})}
\end{align}

While the multidimensional Bayes factor is not analogous to the frequentist visual p-value, it does provide the foundation for the calculation of a marginal Bayes factor that is similar to the p-value calculation in \autoref{eqn:sim-pmf}.

\subsection{Marginal Bayes Factors for Target Plots}

Working from the Beta-Binomial marginal distribution in \autoref{eqn:marginal-model-specification}, we can similarly derive a marginal Bayes factor that could be calculated for any panel $i$ in the $m$-panel lineup. In most cases, it would not be particularly useful to calculate a Bayes factor for null plots in the lineup; as in the visual p-value calculation, we are primarily concerned with the number of data detections compared to the aggregate number of null plot detections. Supposing that the data is shown in panel $i$, we can derive the Bayes factor for a  single target lineup as:

  % Derive bayes factors for plots based on one-target lineups
\begin{align}
BF(M_1, M_2)_i  =& \frac{\displaystyle\int_\theta p(\theta | \alpha_{M_1}) f(K, c_i | \theta, \alpha_{M_1}) d\theta}
{\displaystyle\int_\theta p(\theta | \alpha_{M_2}) f(K, c_i | \theta, \alpha_{M_2}) d\theta} \nonumber\\
= &\frac{\displaystyle\int_\theta \binom{K}{c_i} \theta^{c_i} (1 - \theta)^{K - c_i}
  \frac{1}{B(\alpha_{M_1}, (m-1) \alpha_{M_1})} \theta^{\alpha_{M_1}} (1-\theta)^{(m-1) \alpha_{M_1}} d\theta}
{\displaystyle\int_\theta \binom{K}{c_i} \theta^{c_i} (1 - \theta)^{K - c_i}
  \frac{1}{B(\alpha_{M_2}, (m-1) \alpha_{M_2})} \theta^{\alpha_{M_2}} (1-\theta)^{(m-1) \alpha_{M_2}} d\theta}\nonumber\\
= &\frac{B(\alpha_{M_2}, (m-1)\alpha_{M_2})}{B(\alpha_{M_1}, (m-1)\alpha_{M_1})}
\frac{B(c_i + \alpha_{M_1}, K - c_i + (m-1)\alpha_{M_1})}{B(c_i + \alpha_{M_2}, K - c_i + (m-1)\alpha_{M_2})} \times \nonumber\\
&\frac{\displaystyle\int_\theta \frac{1}{B(c_i + \alpha_{M_1}, K - c_i + (m-1)\alpha_{M_1})} \theta^{c_i + \alpha_{M_1} - 1} (1-\theta)^{K - c_i + (m-1)\alpha_{M_1} - 1} d\theta}
{\displaystyle\int_\theta \frac{1}{B(c_i + \alpha_{M_2}, K - c_i + (m-1)\alpha_{M_2})} \theta^{c_i + \alpha_{M_2} - 1} (1-\theta)^{K - c_i + (m-1)\alpha_{M_2} - 1} d\theta}\nonumber\\
= & \frac{B(\alpha_{M_2}, (m-1)\alpha_{M_2})}{B(\alpha_{M_1}, (m-1)\alpha_{M_1})}
\frac{B(c_i + \alpha_{M_1}, K - c_i + (m-1)\alpha_{M_1})}{B(c_i + \alpha_{M_2}, K - c_i + (m-1)\alpha_{M_2})}
\end{align}

A similar derivation replacing $m-1$ with $m_0$, the number of null plots in the lineup, could be used to analyze modifications of the single-target lineup design, such as the study in \citet{vanderplas:2017}.

The marginal beta-binomial model considers the data detections and the aggregated null-plot detections; as a result, the parameters of the posterior beta distribution are $C + \alpha, K - C + (m-1)\alpha$. As discussed in \autoref{sec:alpha}, $\alpha$ can be thought of as providing pseudo-observations for each plot; that is, the effect of $\alpha$ is equivalent to adding $\alpha$ observations to each panel in the lineup.

\subsection{Selection of $\alpha_{M_1}$ and $\alpha_{M_2}$}

The marginal and full Bayes factors derived above depend on parameters $\alpha_{M_1}$ and $\alpha_{M_2}$, where in our formulation $\alpha_{M_1} < \alpha_{M_2}$. We could choose values of $\alpha_{M_{1,2}}$ based on the prior predictive distributions shown in \autoref{fig:prior-predictive}, but it is also useful to assess the effect of different combinations of $\alpha_{M_{1,2}}$ on the resulting Bayes Factor.

\autoref{fig:bayes-factors-alphas} shows Bayes Factors in the marginal case for combinations of $\alpha_1, \alpha_2$ over several different $C$ values, assuming a total of $K=20$ independent evaluations.
<<bayes-factors-alphas, fig.width = 8, fig.height = 4, fig.cap = "Bayes factor values at different levels of $\\alpha_1$ and $\\alpha_2$. If there are large numbers of data panel identifications, the Bayes Factor will be large even with conservative parameter values (e.g. $\\alpha_1$ near 1, $\\alpha_2 =  2$). The choice of alphas is much more impactful when there are fewer data plot identifications. While the criteria for interpretation of Bayes factors vary, a result of $>20$ is generally considered to correspond to strong evidence toward $M_1$ over $M_2$." >>=

  breaks <-  c(2, 5, 10, 20)
data_breaks <- c(1, 3, 5, 8, 10)


p01 <- tidyr::crossing(a1 = seq(.01, 1, .01),
                       a2 = breaks,
                       m = 20,
                       k = 20,
                       c = data_breaks) %>%
  mutate(bf = purrr::pmap_dbl(., bf)) %>%
  mutate(a2f = factor(a2, levels = unique(a2), labels = sprintf("alpha[2] == %f", unique(a2)), ordered = T)) %>%
  ggplot(aes(x = a1, y = bf, color = factor(c), group = factor(c))) +
  geom_line() +
  scale_y_log10("Bayes Factor", breaks = c(1, 10, 100, 1000, 10000)) +
  scale_x_continuous(expression(alpha[1])) +
  scale_color_discrete("# Data\nPanel\nIdentifications\n(K = 20)", guide = F) +
  facet_wrap(~a2f, labeller = "label_parsed")

p02 <- tidyr::crossing(a2 = seq(1.5, 20, by = 0.1),
                       a1 = 1/breaks,
                       m = 20,
                       k = 20,
                       c = data_breaks) %>%
  mutate(bf = purrr::pmap_dbl(., bf)) %>%
  mutate(a2f = factor(a2, levels = unique(a2),
                      labels = sprintf("alpha[2] == ~~%f", unique(a2)),
                      ordered = T)) %>%
  mutate(a1f = factor(a1, levels = 1/rev(breaks),
                      labels = sprintf("alpha[1] == ~~1/%f", rev(breaks)),
                      ordered = T)) %>%
  ggplot(aes(x = a2, y = bf, color = factor(c), group = factor(c))) +
  geom_line() +
  scale_y_log10("Bayes Factor", breaks = c(1, 10, 100, 1000, 10000)) +
  scale_x_continuous(expression(alpha[2])) +
  scale_color_discrete("# Data\nPanel\nIdentifications\n(K = 20)") +
  facet_wrap(~a1f, labeller = "label_parsed")

gridExtra::grid.arrange(p01, p02, nrow = 1, widths = c(.425, .575))
@
  Clearly, the choice of $\alpha_1$ and $\alpha_2$ is important, but in order to get a feel for how the Bayes factor approach might compare to the visual p-value approach, let us set $\alpha_1 = 0.5$ and $\alpha_2 = 2$, which would correspond to relatively weak hyperparameters for both models, and examine the results from three lineups.
The first of these examples, shown in \autoref{fig:turk13-lineup}, is from \citet{loyAreYouNormal2015}, a study which compared different q-q plots.
We can see that there is no significant support for the choice of model 1 over model 2, or vice versa, when considering the target panel selections compared to the aggregate null panel selections.
The target panel, which is in panel 14, had relatively few selections, resulting in a marginal Bayes Factor of 1.03.
The full-model Bayes Factor of \Sexpr{bf_vec(1/2, 2, c = counts_turk13$n)} indicates that there is some evidence that all plots are not equally likely to be selected, primarily due to the multiple selections of a null plot in panel 4.
The marginal Bayes Factor for panel 4 is \Sexpr{bf(1/2, 2, c = counts_turk13$n)[4]}, which would correspond to weak support for $M_1$ over $M_2$ if panel 4 had been contained the data.
The corresponding visual p-value for this plot calculated from the binomial distribution~\citep{majumder2013validation} is \Sexpr{sprintf("%0.4g", vis_p_value_orig(counts_turk13$n, sum(counts_turk13$n))[14])} and the beta-binomial p-value with $\alpha = 1$ is \Sexpr{sprintf("%0.4g", vis_p_value(counts_turk13$n, sum(counts_turk13$n))[14])}.
In this example, the conclusion would be the same for frequentist and Bayesian tests of the hypothesis that every plot is approximately likely to be selected.

<<turk13-lineup, fig.cap = sprintf("A lineup from \\citet{loyAreYouNormal2015} which was evaluated a total of %d times. Number of selections $c_i$ are shown at the top left of each panel; the calculated Bayes Factors with $\\alpha_1 = 0.5$ and $\\alpha_2 = 2$ is shown at the bottom right of the target panel (panel 14). As panel 4 was selected more frequently than panel 14, there is no significant information in favor of model 1 (the target plot is more likely to be selected than the nulls) over model 2. The multidimensional (whole plot) bayes factor with the same $\\alpha_1,\\alpha_2$ values is %.2f, indicating that there is weak to moderate evidence that all plots are not equally likely to be selected; that is, that model 1 better aligns with the observed data than model 2. Note that this evidence support is primarily due to the multiple selections of panel 4, which shows data generated by the null data model.", sum(counts_turk13$n), bf_vec(1/2, 2, c = counts_turk13$n)), fig.width = 6, fig.height = 6/5*4.5, fig.align='center', out.width = ".66\\textwidth">>=
  t13plot_data %>%
  ggplot() +
  geom_ribbon(aes(x = naive1.env.fit.value, ymin = naive1.env.lower, ymax = naive1.env.upper), alpha = .1) +
  geom_point(aes(x = naive1.qq.x, y = naive1.qq.y)) +
  geom_abline(aes(slope = 1, intercept = 0), color = "grey30") +
  geom_text(aes(x = -Inf, y = Inf, label = sprintf("c[%d] == %.0f", .sample_inner, n)),
            hjust = -0.2, vjust = 1, parse = T, data = counts_turk13, inherit.aes = F) +
  geom_text(aes(x = Inf, y = -Inf, label = sprintf("BF == %.2f", bf)),
            vjust = -0.2, hjust = 1, parse = T, data = filter(counts_turk13, .sample_inner == 14), inherit.aes = F) +
  facet_wrap(~.sample_inner) +
  theme(axis.text = element_blank(), axis.title = element_blank(), axis.ticks = element_blank())
@

  One advantage of the Multinomial-Dirichlet model presented in this paper relative to the strict binomial method is that it seamlessly incorporates multiple target plot selections: a participant who selects $p$ panels of a lineup would contribute $1/p$ votes to each panel's total.

Participants selected the data plot in \autoref{fig:turk13-lineup} in \Sexpr{counts_turk13$n[14]} of \Sexpr{sum(counts_turk13$n)} evaluations; we should also examine how the Bayes factor performs when the null plots are much less likely to be selected. \autoref{fig:turk6-lineup} shows a lineup with overwhelming evidence suggesting that the target plot is disproportionately selected.
<<turk6-lineup, fig.cap = sprintf("A lineup from \\todo{cite?} which was evaluated a total of %d times. Number of selections $c_i$ are shown at the top left of each panel; the calculated Bayes Factors with $\\alpha_1 = 0.5$ and $\\alpha_2 = 2$ is shown at the bottom right of the target panel (panel 4). The multidimensional (whole plot) bayes factor with the same $\\alpha_1,\\alpha_2$ values is %9.3e, indicating that there is overwhelming evidence that all plots are not equally likely to be selected; that is, that model 1 better aligns with the observed data than model 2.", sum(counts_t6_sig$n), bf_vec(1/2, 2, c = counts_t6_sig$n)), fig.width = 6, fig.height = 6/5*4.5, fig.align='center', out.width = ".66\\textwidth">>=
ggplot(t6_sig_data, aes(x = group, y = vals)) +
  geom_boxplot(outlier.colour = 'NA', colour = "grey60", width = 0.75) +
  geom_point(aes(x = newx, y = newy, colour = factor(group)), shape = 1, size = 1) +
  scale_color_discrete(guide = F) +
  facet_wrap(~.sample, ncol = 5) +
  theme(axis.title = element_blank(), axis.text = element_blank(), axis.ticks = element_blank()) +
  xlab("") + scale_y_continuous(expand = c(0.1,0)) +
  geom_text(aes(x = -Inf, y = Inf, label = sprintf("c[%d] == %.0f", .sample, n)),
            hjust = -0.2, vjust = 1, parse = T, data = counts_t6_sig, inherit.aes = F) +
  geom_text(aes(x = Inf, y = -Inf, label = sprintf("BF == %9.3e", bf)),
            vjust = -0.2, hjust = 1, parse = T, data = filter(counts_t6_sig, .sample == 4), inherit.aes = F)
@
The binomial model visual p-value for this plot calculated as in \citet{majumder2013validation} is \Sexpr{sprintf("%0.4g", vis_p_value_orig(counts_t6_sig$n, sum(counts_t6_sig$n))[4])} and the beta-binomial p-value with $\alpha = 1$ is \Sexpr{sprintf("%0.4g", vis_p_value(counts_t6_sig$n, sum(counts_t6_sig$n))[4])}. The amount of evidence suggesting that the hypothesis that all plots are equally likely to be selected is staggering no matter which method is employed.


<<turk6-ambiguous, fig.cap = sprintf("A lineup from \\todo{cite?} which was evaluated a total of %d times. Number of selections $c_i$ are shown at the top left of each panel; the calculated Bayes Factors with $\\alpha_1 = 0.5$ and $\\alpha_2 = 2$ is shown at the bottom right of the target panel (panel 8). The multidimensional (whole plot) bayes factor with the same $\\alpha_1,\\alpha_2$ values is %9.3e, indicating that there is overwhelming evidence that all plots are not equally likely to be selected; that is, that model 1 better aligns with the observed data than model 2.", sum(counts_t6_sig$n), bf_vec(1/2, 2, c = counts_t6_sig$n)), fig.width = 6, fig.height = 6/5*4.5, fig.align='center', out.width = ".66\\textwidth">>=
ggplot(t6_ambig_data, aes(y = vals, fill = factor(group))) +
  geom_boxplot() +
  scale_fill_discrete(guide = F) +
  facet_wrap(~.sample, ncol = 5) +
  theme(axis.title = element_blank(), axis.text = element_blank(), axis.ticks = element_blank()) +
  xlab("") + scale_y_continuous(expand = c(0.1,0)) +
  geom_text(aes(x = -Inf, y = Inf, label = sprintf("c[%d] == %.0f", .sample, n)),
            hjust = -0.2, vjust = 1, parse = T, data = counts_t6_ambig, inherit.aes = F) +
  geom_text(aes(x = Inf, y = -Inf, label = sprintf("BF == %9.3e", bf)),
            vjust = -0.2, hjust = 1, parse = T, data = filter(counts_t6_ambig, .sample == 8), inherit.aes = F)
@

Finally, it is good to assess the Bayes factor's performance on lineups which are somewhat ambiguous, with selections of the target plot as well as frequent selection of a null plot. Such a lineup is shown in \autoref{fig:turk6-ambiguous}, where panel 8 is the target panel and has a Bayes Factor of \Sexpr{sprintf("%.2f", filter(counts_t6_ambig, .sample == 8)$bf)}. The corresponding binomial visual p-value is \Sexpr{sprintf("%.4g", vis_p_value_orig(counts_t6_ambig$n, sum(counts_t6_ambig$n))[8])} and the beta-binomial visual p-value with $\alpha=1$ is \Sexpr{sprintf("%.4g", vis_p_value(counts_t6_ambig$n, sum(counts_t6_ambig$n))[8])}. All methods provide some indication that the panels are not equally likely to be selected, but the support from the Bayes Factor might be best stated as ``moderate" while the p-values would be considered ``highly significant" by most standards. This is much more consistent with a ``gut check" when considering the selection counts in \autoref{fig:turk6-ambiguous}; it is certainly not reasonable to believe that all panels are equally likely to be selected, as 14 of the 20 panels were not selected at all, but the target plot was selected less than half of the time, which does not seem to correspond to ``overwhelming evidence" that the target plot is more likely to be selected.

The Bayes factors presented in this section provide another way to evaluate visual inference experiments, but it is obvious that the selection of $\alpha_1$ and $\alpha_2$ have a large effect on the results. It is generally useful in these situations to examine past data with the goal of determining a reasonable range of values for $\alpha$.

% Bayes factors become more useful, however, when used to examine a two-target lineup, where two data generating models are competing against each other, with null plots drawn from a mixture of the two distributions. In this case, for target panels $i, j$ in a $m$-panel lineup, we can calculate three single-panel bayes factors based on models $M_A$, that the first data model target is more likely to be selected, $M_B$, that the second data model target is more likely to be selected ($M_A$ and $M_B$ are separate instances of $M_1$ in the single target case, representing different target panels), and $M_U$, a generalization of $M_2$ in the single target case, which suggests that all plots are equally likely to be selected.
% \begin{align}
% BF(M_A, M_U)_i &=  \frac{B(\alpha_{M_U}, (m-2)\alpha_{M_U})}{B(\alpha_{M_A}, (m-2)\alpha_{M_1})}
% \frac{B(c_i + \alpha_{M_A}, K - c_i - c_j + (m-2)\alpha_{M_A})}{B(c_i + \alpha_{M_U}, K - c_i - c_j + (m-2)\alpha_{M_U})}\\
% BF(M_B, M_U)_j &=  \frac{B(\alpha_{M_U}, (m-2)\alpha_{M_B})}{B(\alpha_{M_2}, (m-2)\alpha_{M_2})}
% \frac{B(c_j + \alpha_{M_B}, K - c_i - c_j + (m-2)\alpha_{M_2})}{B(c_j + \alpha_{M_U}, K - c_i - c_j + (m-2)\alpha_{M_U})}\\
% \end{align}
%
% The first two, $BF(M_1, M_2)_i$ and  $BF(M_1, M_2)_j$, examine the relative likelihood of model 1 vs. model 2. \todo{The third bayes factor compares the probability of selection of plot $i$ with the probability of selection of plot $j$ to establish which data generation model is more visually salient.}
% \todo{Possibly go into two-target lineups?}
\end{document}
